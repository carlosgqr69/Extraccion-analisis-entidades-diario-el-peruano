{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0017f73-465e-4f8b-ae2f-1a21a5cdf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPARACIÓN PARA FINE-TUNING\n",
      "======================================================================\n",
      "\n",
      "1. VERIFICACIÓN DE GPU\n",
      "----------------------------------------------------------------------\n",
      "PyTorch version: 2.3.1\n",
      "CUDA disponible: True\n",
      "GPU detectada: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Memoria GPU: 4.0 GB\n",
      "Estado: Listo para fine-tuning\n",
      "\n",
      "2. CARGA DE DATOS\n",
      "----------------------------------------------------------------------\n",
      "Cargando datos del CSV...\n",
      "Datos cargados: 17,008 registros\n",
      "\n",
      "Distribución por tipo:\n",
      "  DISOLUCION: 3,689\n",
      "  REMATE: 9,515\n",
      "  JUNTA_ACCIONISTAS: 3,804\n",
      "\n",
      "======================================================================\n",
      "LISTO PARA CREAR DATASET\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# FINE-TUNING - PREPARACIÓN\n",
    "# =========================================================================\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARACIÓN PARA FINE-TUNING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Verificar GPU\n",
    "print(\"1. VERIFICACIÓN DE GPU\")\n",
    "print(\"-\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"Estado: Listo para fine-tuning\")\n",
    "else:\n",
    "    print(\"ADVERTENCIA: No hay GPU disponible\")\n",
    "    print(\"El fine-tuning en CPU tardará 8-12 horas\")\n",
    "\n",
    "# Cargar datos (solo si no están cargados)\n",
    "print(\"\\n2. CARGA DE DATOS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    # Verificar si df_filtrado ya existe\n",
    "    print(f\"Datos ya cargados: {len(df_filtrado):,} registros\")\n",
    "except NameError:\n",
    "    # Si no existe, cargar\n",
    "    print(\"Cargando datos del CSV...\")\n",
    "    df = pd.read_csv(\"base_datos_final/base_datos_completa.csv\", low_memory=False)\n",
    "    tipos_relevantes = ['JUNTA_ACCIONISTAS', 'DISOLUCION', 'REMATE']\n",
    "    df_filtrado = df[df['tipo'].isin(tipos_relevantes)].copy()\n",
    "    print(f\"Datos cargados: {len(df_filtrado):,} registros\")\n",
    "\n",
    "print(f\"\\nDistribución por tipo:\")\n",
    "for tipo in ['DISOLUCION', 'REMATE', 'JUNTA_ACCIONISTAS']:\n",
    "    count = len(df_filtrado[df_filtrado['tipo'] == tipo])\n",
    "    print(f\"  {tipo}: {count:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LISTO PARA CREAR DATASET\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08da08b9-db95-40a4-ba64-13fc825e5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREACIÓN DE DATASET PARA FINE-TUNING\n",
      "Metodología: Rangan & Yin (2024) - RAG enhanced fine-tuning\n",
      "======================================================================\n",
      "\n",
      "Datos disponibles: 17,008 registros\n",
      "Tipos: {'REMATE': 9515, 'JUNTA_ACCIONISTAS': 3804, 'DISOLUCION': 3689}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# FINE-TUNING - CREACIÓN DEL DATASET\n",
    "# Metodología basada en Rangan & Yin (2024) y González & Santa (2024)\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREACIÓN DE DATASET PARA FINE-TUNING\")\n",
    "print(\"Metodología: Rangan & Yin (2024) - RAG enhanced fine-tuning\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Verificar datos disponibles\n",
    "print(f\"Datos disponibles: {len(df_filtrado):,} registros\")\n",
    "print(f\"Tipos: {df_filtrado['tipo'].value_counts().to_dict()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd143402-68d1-41a9-a2e5-7378e761b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando ejemplos Tipo 1: Extracción de información...\n",
      "Ejemplos de extracción creados: 600\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# TIPO 1: EXTRACCIÓN DE INFORMACIÓN (40% del dataset)\n",
    "# =========================================================================\n",
    "\n",
    "print(\"Generando ejemplos Tipo 1: Extracción de información...\")\n",
    "\n",
    "ejemplos_extraccion = []\n",
    "\n",
    "# Tomar muestra balanceada\n",
    "for tipo in ['DISOLUCION', 'REMATE', 'JUNTA_ACCIONISTAS']:\n",
    "    df_tipo = df_filtrado[df_filtrado['tipo'] == tipo]\n",
    "    muestra = df_tipo.sample(min(200, len(df_tipo)), random_state=42)\n",
    "    \n",
    "    for idx, row in muestra.iterrows():\n",
    "        texto = str(row['texto_completo'])[:800]\n",
    "        \n",
    "        if tipo == 'DISOLUCION':\n",
    "            # Construir output esperado\n",
    "            ruc_clean = str(row.get('ruc', 'No especificado'))\n",
    "            if ruc_clean == 'nan':\n",
    "                ruc_clean = 'No especificado'\n",
    "            \n",
    "            output = f\"\"\"Información extraída del aviso de disolución:\n",
    "\n",
    "Tipo de documento: Disolución y Liquidación\n",
    "Empresa: {row.get('empresa', 'No especificado')}\n",
    "RUC: {ruc_clean}\n",
    "Fecha de publicación: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Fuente: Diario Oficial El Peruano\n",
    "\"\"\"\n",
    "            \n",
    "            ejemplo = {\n",
    "                \"instruction\": \"Extrae la información estructurada del siguiente aviso legal de disolución publicado en el Diario El Peruano. Identifica: tipo de documento, empresa, RUC y fecha.\",\n",
    "                \"input\": texto,\n",
    "                \"output\": output\n",
    "            }\n",
    "            \n",
    "        elif tipo == 'REMATE':\n",
    "            output = f\"\"\"Información extraída del aviso de remate:\n",
    "\n",
    "Tipo de documento: Remate Judicial\n",
    "Ubicación del inmueble: {row.get('ubicacion', 'No especificado')}\n",
    "Valor base: {row.get('base', 'No especificado')}\n",
    "Fecha de remate: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Fuente: Diario Oficial El Peruano\n",
    "\"\"\"\n",
    "            \n",
    "            ejemplo = {\n",
    "                \"instruction\": \"Extrae la información estructurada del siguiente aviso de remate judicial. Identifica: ubicación, valor base y fecha.\",\n",
    "                \"input\": texto,\n",
    "                \"output\": output\n",
    "            }\n",
    "            \n",
    "        else:  # JUNTA_ACCIONISTAS\n",
    "            ruc_clean = str(row.get('ruc', 'No especificado'))\n",
    "            if ruc_clean == 'nan':\n",
    "                ruc_clean = 'No especificado'\n",
    "            \n",
    "            output = f\"\"\"Información extraída del aviso de junta:\n",
    "\n",
    "Tipo de documento: Convocatoria a Junta General de Accionistas\n",
    "Empresa: {row.get('empresa', 'No especificado')}\n",
    "RUC: {ruc_clean}\n",
    "Fecha de junta: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Fuente: Diario Oficial El Peruano\n",
    "\"\"\"\n",
    "            \n",
    "            ejemplo = {\n",
    "                \"instruction\": \"Extrae la información estructurada del siguiente aviso de convocatoria a junta de accionistas. Identifica: empresa, RUC y fecha.\",\n",
    "                \"input\": texto,\n",
    "                \"output\": output\n",
    "            }\n",
    "        \n",
    "        ejemplos_extraccion.append(ejemplo)\n",
    "\n",
    "print(f\"Ejemplos de extracción creados: {len(ejemplos_extraccion)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32b4ade-dbd0-4b6b-aff6-4046b7e5eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando ejemplos Tipo 2: Formateo profesional...\n",
      "Ejemplos de formateo creados: 450\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# TIPO 2: FORMATEO PROFESIONAL (30% del dataset)\n",
    "# =========================================================================\n",
    "\n",
    "print(\"\\nGenerando ejemplos Tipo 2: Formateo profesional...\")\n",
    "\n",
    "ejemplos_formateo = []\n",
    "\n",
    "for tipo in ['DISOLUCION', 'REMATE', 'JUNTA_ACCIONISTAS']:\n",
    "    df_tipo = df_filtrado[df_filtrado['tipo'] == tipo]\n",
    "    muestra = df_tipo.sample(min(150, len(df_tipo)), random_state=43)\n",
    "    \n",
    "    for idx, row in muestra.iterrows():\n",
    "        # Input: datos desordenados (simular query real)\n",
    "        if tipo == 'DISOLUCION':\n",
    "            input_text = f\"Empresa {row.get('empresa', 'N/A')} disuelta, RUC {row.get('ruc', 'N/A')}, fecha {row.get('fecha', 'N/A')}\"\n",
    "            \n",
    "            output_text = f\"\"\"AVISO DE DISOLUCIÓN Y LIQUIDACIÓN\n",
    "\n",
    "De conformidad con el artículo 412 de la Ley General de Sociedades, se comunica:\n",
    "\n",
    "Empresa: {row.get('empresa', 'No especificado')}\n",
    "RUC: {row.get('ruc', 'No especificado')}\n",
    "Fecha de disolución: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Publicado en el Diario Oficial El Peruano conforme a ley.\n",
    "\"\"\"\n",
    "        \n",
    "        elif tipo == 'REMATE':\n",
    "            input_text = f\"Remate ubicación {row.get('ubicacion', 'N/A')}, base {row.get('base', 'N/A')}, fecha {row.get('fecha', 'N/A')}\"\n",
    "            \n",
    "            output_text = f\"\"\"AVISO DE REMATE JUDICIAL\n",
    "\n",
    "Por disposición judicial, se convoca a remate público:\n",
    "\n",
    "Bien inmueble ubicado en: {row.get('ubicacion', 'No especificado')}\n",
    "Valor base: {row.get('base', 'No especificado')}\n",
    "Fecha de remate: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Publicado en el Diario Oficial El Peruano.\n",
    "\"\"\"\n",
    "        \n",
    "        else:  # JUNTA\n",
    "            input_text = f\"Junta de {row.get('empresa', 'N/A')}, fecha {row.get('fecha', 'N/A')}\"\n",
    "            \n",
    "            output_text = f\"\"\"CONVOCATORIA A JUNTA GENERAL DE ACCIONISTAS\n",
    "\n",
    "Se convoca a los señores accionistas de:\n",
    "\n",
    "Empresa: {row.get('empresa', 'No especificado')}\n",
    "RUC: {row.get('ruc', 'No especificado')}\n",
    "Fecha de junta: {row.get('fecha', 'No especificado')}\n",
    "\n",
    "Publicado conforme al artículo 43 de la Ley General de Sociedades.\n",
    "\"\"\"\n",
    "        \n",
    "        ejemplo = {\n",
    "            \"instruction\": \"Formatea la siguiente información en un aviso legal profesional, siguiendo la estructura estándar del Diario El Peruano.\",\n",
    "            \"input\": input_text,\n",
    "            \"output\": output_text\n",
    "        }\n",
    "        \n",
    "        ejemplos_formateo.append(ejemplo)\n",
    "\n",
    "print(f\"Ejemplos de formateo creados: {len(ejemplos_formateo)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35afaebc-69eb-4f48-a911-32c6b641ce33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando ejemplos Tipo 3: Pregunta-respuesta...\n",
      "Ejemplos de QA creados: 450\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# TIPO 3: PREGUNTA-RESPUESTA CON CONTEXTO (30% del dataset)\n",
    "# =========================================================================\n",
    "import random\n",
    "\n",
    "print(\"\\nGenerando ejemplos Tipo 3: Pregunta-respuesta...\")\n",
    "\n",
    "ejemplos_qa = []\n",
    "\n",
    "# Plantillas de preguntas\n",
    "plantillas_preguntas = {\n",
    "    'DISOLUCION': [\n",
    "        \"¿Cuál es el nombre de la empresa disuelta?\",\n",
    "        \"¿Qué RUC tiene la empresa?\",\n",
    "        \"¿En qué fecha se publicó la disolución?\",\n",
    "        \"¿Qué tipo de documento legal es este?\"\n",
    "    ],\n",
    "    'REMATE': [\n",
    "        \"¿Dónde está ubicado el inmueble?\",\n",
    "        \"¿Cuál es el valor base del remate?\",\n",
    "        \"¿Cuándo se realizará el remate?\",\n",
    "        \"¿Qué tipo de aviso es este?\"\n",
    "    ],\n",
    "    'JUNTA_ACCIONISTAS': [\n",
    "        \"¿Qué empresa convoca a junta?\",\n",
    "        \"¿Cuándo se realizará la junta?\",\n",
    "        \"¿Cuál es el RUC de la empresa?\",\n",
    "        \"¿Qué tipo de reunión se convoca?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for tipo in ['DISOLUCION', 'REMATE', 'JUNTA_ACCIONISTAS']:\n",
    "    df_tipo = df_filtrado[df_filtrado['tipo'] == tipo]\n",
    "    muestra = df_tipo.sample(min(150, len(df_tipo)), random_state=44)\n",
    "    \n",
    "    for idx, row in muestra.iterrows():\n",
    "        texto_contexto = str(row['texto_completo'])[:600]\n",
    "        pregunta = random.choice(plantillas_preguntas[tipo])\n",
    "        \n",
    "        # Generar respuesta según pregunta\n",
    "        if \"nombre\" in pregunta.lower() or \"empresa\" in pregunta.lower():\n",
    "            respuesta = f\"La empresa es {row.get('empresa', 'no se especifica en el documento')}.\"\n",
    "        elif \"ruc\" in pregunta.lower():\n",
    "            ruc_val = row.get('ruc', 'nan')\n",
    "            if str(ruc_val) == 'nan':\n",
    "                respuesta = \"El RUC no se especifica en el documento.\"\n",
    "            else:\n",
    "                respuesta = f\"El RUC de la empresa es {ruc_val}.\"\n",
    "        elif \"fecha\" in pregunta.lower() or \"cuándo\" in pregunta.lower():\n",
    "            respuesta = f\"La fecha es {row.get('fecha', 'no se especifica en el documento')}.\"\n",
    "        elif \"ubicado\" in pregunta.lower() or \"ubicación\" in pregunta.lower():\n",
    "            respuesta = f\"El inmueble está ubicado en {row.get('ubicacion', 'no se especifica en el documento')}.\"\n",
    "        elif \"valor base\" in pregunta.lower():\n",
    "            respuesta = f\"El valor base es {row.get('base', 'no se especifica en el documento')}.\"\n",
    "        elif \"tipo\" in pregunta.lower():\n",
    "            if tipo == 'DISOLUCION':\n",
    "                respuesta = \"Este es un aviso de disolución y liquidación de sociedad.\"\n",
    "            elif tipo == 'REMATE':\n",
    "                respuesta = \"Este es un aviso de remate judicial.\"\n",
    "            else:\n",
    "                respuesta = \"Esta es una convocatoria a junta general de accionistas.\"\n",
    "        else:\n",
    "            respuesta = \"La información solicitada no se encuentra claramente especificada en el documento.\"\n",
    "        \n",
    "        ejemplo = {\n",
    "            \"instruction\": f\"Lee el siguiente documento legal y responde la pregunta de manera precisa y concisa.\\n\\nDocumento:\\n{texto_contexto}\\n\\nPregunta: {pregunta}\",\n",
    "            \"input\": \"\",\n",
    "            \"output\": respuesta\n",
    "        }\n",
    "        \n",
    "        ejemplos_qa.append(ejemplo)\n",
    "\n",
    "print(f\"Ejemplos de QA creados: {len(ejemplos_qa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76feb4ce-7394-4af8-8725-093cc3dd8305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMBINANDO DATASET FINAL\n",
      "======================================================================\n",
      "\n",
      "Total de ejemplos: 1500\n",
      "  Extracción: 600 (40.0%)\n",
      "  Formateo: 450 (30.0%)\n",
      "  QA: 450 (30.0%)\n",
      "\n",
      "Split:\n",
      "  Train: 1350 ejemplos (90%)\n",
      "  Validation: 150 ejemplos (10%)\n",
      "\n",
      "Datasets guardados en: fine_tuning_data/\n",
      "  - dataset_train.json\n",
      "  - dataset_val.json\n",
      "\n",
      "======================================================================\n",
      "EJEMPLOS DEL DATASET\n",
      "======================================================================\n",
      "\n",
      "Ejemplo 1 (Extracción):\n",
      "{\n",
      "  \"instruction\": \"Lee el siguiente documento legal y responde la pregunta de manera precisa y concisa.\\n\\nDocumento:\\nREMATE: [INDICAR DÍA, MES Y AÑO] LUGAR, FECHA Y HORA DE LA EXHIBICIÓN DE LOS BIENES INMUEBLES: Los bienes inmuebles pueden ser visitados en las ubicaciones descritas en cada ITEM. Carta N° [INDICAR N° DE CARTA] – [AÑO] – [MEMBRETE DE LA ENTIDAD PRIVADA SUPERVISORA] LOS BIENES SE ADJUDICARÁN EN EL ESTADO Y CONDICIONES EN LAS QUE SE ENCUENTRAN, Señores SIN LUGAR A RECLAMO POSTERI...\n",
      "\n",
      "Ejemplo 2 (Formateo):\n",
      "{\n",
      "  \"instruction\": \"Formatea la siguiente información en un aviso legal profesional, siguiendo la estructura estándar del Diario El Peruano.\",\n",
      "  \"input\": \"Remate ubicación nan, base nan, fecha 2025-06-24\",\n",
      "  \"output\": \"AVISO DE REMATE JUDICIAL\\n\\nPor disposición judicial, se convoca a remate público:\\n\\nBien inmueble ubicado en: nan\\nValor base: nan\\nFecha de remate: 2025-06-24\\n\\nPublicado en el Diario Oficial El Peruano.\\n\"\n",
      "}...\n",
      "\n",
      "Ejemplo 3 (QA):\n",
      "{\n",
      "  \"instruction\": \"Lee el siguiente documento legal y responde la pregunta de manera precisa y concisa.\\n\\nDocumento:\\nREMATE: [INDICAR DÍA, MES Y AÑO] LUGAR, FECHA Y HORA DE LA EXHIBICIÓN DE LOS BIENES INMUEBLES: Los bienes inmuebles pueden ser visitados en las ubicaciones descritas en cada ITEM. Carta N° [INDICAR N° DE CARTA] – [AÑO] – [MEMBRETE DE LA ENTIDAD PRIVADA SUPERVISORA] LOS BIENES SE ADJUDICARÁN EN EL ESTADO Y CONDICIONES EN LAS QUE SE ENCUENTRAN, Señores SIN LUGAR A RECLAMO POSTERI...\n",
      "\n",
      "Dataset listo para fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# COMBINAR Y MEZCLAR DATASET\n",
    "# =========================================================================\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMBINANDO DATASET FINAL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Combinar todos los ejemplos\n",
    "dataset_completo = ejemplos_extraccion + ejemplos_formateo + ejemplos_qa\n",
    "\n",
    "# Mezclar aleatoriamente\n",
    "random.seed(42)\n",
    "random.shuffle(dataset_completo)\n",
    "\n",
    "# Estadísticas\n",
    "total = len(dataset_completo)\n",
    "print(f\"Total de ejemplos: {total}\")\n",
    "print(f\"  Extracción: {len(ejemplos_extraccion)} ({len(ejemplos_extraccion)/total*100:.1f}%)\")\n",
    "print(f\"  Formateo: {len(ejemplos_formateo)} ({len(ejemplos_formateo)/total*100:.1f}%)\")\n",
    "print(f\"  QA: {len(ejemplos_qa)} ({len(ejemplos_qa)/total*100:.1f}%)\")\n",
    "\n",
    "# Split train/validation (90/10)\n",
    "split_idx = int(len(dataset_completo) * 0.9)\n",
    "dataset_train = dataset_completo[:split_idx]\n",
    "dataset_val = dataset_completo[split_idx:]\n",
    "\n",
    "print(f\"\\nSplit:\")\n",
    "print(f\"  Train: {len(dataset_train)} ejemplos (90%)\")\n",
    "print(f\"  Validation: {len(dataset_val)} ejemplos (10%)\")\n",
    "\n",
    "# Guardar\n",
    "output_dir = Path(\"fine_tuning_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_dir / \"dataset_train.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(dataset_train, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(output_dir / \"dataset_val.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(dataset_val, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nDatasets guardados en: {output_dir}/\")\n",
    "print(\"  - dataset_train.json\")\n",
    "print(\"  - dataset_val.json\")\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EJEMPLOS DEL DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nEjemplo 1 (Extracción):\")\n",
    "print(json.dumps(dataset_train[0], indent=2, ensure_ascii=False)[:500] + \"...\")\n",
    "\n",
    "print(\"\\nEjemplo 2 (Formateo):\")\n",
    "ej_formateo = [e for e in dataset_train if \"Formatea\" in e['instruction']][0]\n",
    "print(json.dumps(ej_formateo, indent=2, ensure_ascii=False)[:500] + \"...\")\n",
    "\n",
    "print(\"\\nEjemplo 3 (QA):\")\n",
    "ej_qa = [e for e in dataset_train if \"Pregunta:\" in e['instruction']][0]\n",
    "print(json.dumps(ej_qa, indent=2, ensure_ascii=False)[:500] + \"...\")\n",
    "\n",
    "print(\"\\nDataset listo para fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d23a12-94d1-4e77-beaa-c337a35bf17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INSTALANDO LIBRERÍAS PARA FINE-TUNING\n",
      "======================================================================\n",
      "\n",
      "Instalando librerías necesarias...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Verificando instalaciones...\n",
      "Transformers: 4.57.3\n",
      "PEFT: 0.18.1\n",
      "BitsAndBytes: OK\n",
      "TRL: 0.8.6\n",
      "Accelerate: 1.12.0\n",
      "Datasets: 4.4.2\n",
      "\n",
      "======================================================================\n",
      "INSTALACIÓN COMPLETADA\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# INSTALACIÓN DE LIBRERÍAS (SIN UNSLOTH)\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INSTALANDO LIBRERÍAS PARA FINE-TUNING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"Instalando librerías necesarias...\")\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('pip', 'install -q transformers peft bitsandbytes trl accelerate datasets')\n",
    "\n",
    "print(\"\\nVerificando instalaciones...\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"Transformers: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Transformers: ERROR - No instalado\")\n",
    "\n",
    "try:\n",
    "    import peft\n",
    "    print(f\"PEFT: {peft.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"PEFT: ERROR - No instalado\")\n",
    "\n",
    "try:\n",
    "    import bitsandbytes\n",
    "    print(\"BitsAndBytes: OK\")\n",
    "except ImportError:\n",
    "    print(\"BitsAndBytes: ERROR - No instalado\")\n",
    "\n",
    "try:\n",
    "    import trl\n",
    "    print(f\"TRL: {trl.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"TRL: ERROR - No instalado\")\n",
    "\n",
    "try:\n",
    "    import accelerate\n",
    "    print(f\"Accelerate: {accelerate.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Accelerate: ERROR - No instalado\")\n",
    "\n",
    "try:\n",
    "    import datasets\n",
    "    print(f\"Datasets: {datasets.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Datasets: ERROR - No instalado\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSTALACIÓN COMPLETADA\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b3ff70-0b68-4b37-96a0-10059fc28710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers: 4.57.3\n",
      "PEFT: 0.18.1\n",
      "TRL: 0.8.6\n",
      "Accelerate: 1.12.0\n",
      "BitsAndBytes: OK\n",
      "Datasets: 4.4.2\n",
      "\n",
      "TODO INSTALADO\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl\n",
    "import accelerate\n",
    "import datasets\n",
    "\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"PEFT: {peft.__version__}\")\n",
    "print(f\"TRL: {trl.__version__}\")\n",
    "print(f\"Accelerate: {accelerate.__version__}\")\n",
    "print(f\"BitsAndBytes: OK\")\n",
    "print(f\"Datasets: {datasets.__version__}\")\n",
    "print(\"\\nTODO INSTALADO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25f9040-cdd9-443d-ba47-8490da0550be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFIGURACIÓN DEL MODELO TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "======================================================================\n",
      "\n",
      "GPU disponible: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Memoria GPU: 4.0 GB\n",
      "\n",
      "Configurando cuantización 4-bit...\n",
      "Cuantización configurada\n",
      "\n",
      "Cargando Llama3-8B-Instruct...\n",
      "NOTA: Primera descarga tarda 5-10 minutos (descarga ~8GB)\n",
      "Descargas posteriores son instantáneas (usa caché local)\n",
      "Descargando y cargando...\n",
      "\n",
      "Modelo cargado en GPU con cuantización 4-bit\n",
      "\n",
      "Preparando modelo para entrenamiento...\n",
      "Modelo preparado\n",
      "\n",
      "Configurando adaptadores LoRA...\n",
      "LoRA configurado\n",
      "\n",
      "======================================================================\n",
      "ESTADÍSTICAS DEL MODELO\n",
      "======================================================================\n",
      "Parámetros totales: 628,221,952\n",
      "Parámetros entrenables (LoRA): 12,615,680\n",
      "Porcentaje entrenable: 2.01%\n",
      "Memoria GPU usada: ~1.0 GB\n",
      "\n",
      "======================================================================\n",
      "MODELO LISTO PARA ENTRENAMIENTO\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CONFIGURACIÓN DEL MODELO TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "# =========================================================================\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURACIÓN DEL MODELO TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Verificar GPU\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\\n\")\n",
    "\n",
    "# Configuración de cuantización 4-bit\n",
    "print(\"Configurando cuantización 4-bit...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "print(\"Cuantización configurada\\n\")\n",
    "\n",
    "# Cargar modelo base\n",
    "print(\"Cargando Llama3-8B-Instruct...\")\n",
    "print(\"NOTA: Primera descarga tarda 5-10 minutos (descarga ~8GB)\")\n",
    "print(\"Descargas posteriores son instantáneas (usa caché local)\")\n",
    "print(\"Descargando y cargando...\\n\")\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(\"Modelo cargado en GPU con cuantización 4-bit\\n\")\n",
    "\n",
    "# Preparar para entrenamiento\n",
    "print(\"Preparando modelo para entrenamiento...\")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(\"Modelo preparado\\n\")\n",
    "\n",
    "# Configurar LoRA\n",
    "print(\"Configurando adaptadores LoRA...\")\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                    # Rank (dimensión de matrices LoRA)\n",
    "    lora_alpha=32,           # Scaling factor\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",      # Attention layers\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",         # MLP layers\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA configurado\\n\")\n",
    "\n",
    "# Estadísticas\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_pct = 100 * trainable_params / total_params\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESTADÍSTICAS DEL MODELO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Parámetros totales: {total_params:,}\")\n",
    "print(f\"Parámetros entrenables (LoRA): {trainable_params:,}\")\n",
    "print(f\"Porcentaje entrenable: {trainable_pct:.2f}%\")\n",
    "print(f\"Memoria GPU usada: ~{torch.cuda.memory_allocated()/1024**3:.1f} GB\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"MODELO LISTO PARA ENTRENAMIENTO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ce8f1c-73d9-4bb9-b860-bdfc4f1c063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando rich...\n",
      "Instalado. Ahora prueba de nuevo la celda de entrenamiento.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Instalando rich...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"rich\"])\n",
    "\n",
    "print(\"Instalado. Ahora prueba de nuevo la celda de entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11af02f0-8114-46d3-9ab7-44ab34012759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPARACIÓN DEL ENTRENAMIENTO\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a8be8c918f4ee0896e25e73a777007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3702a89a04b248fca111b9c2def3189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1350 ejemplos\n",
      "Validation: 150 ejemplos\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210949b00cc5421bb3208c82d1afc322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INICIANDO ENTRENAMIENTO\n",
      "======================================================================\n",
      "\n",
      "Configuración:\n",
      "  Batch size efectivo: 8\n",
      "  Max steps: 300\n",
      "  Learning rate: 2e-4\n",
      "\n",
      "Tiempo estimado: 45-60 minutos con TinyLlama\n",
      "El progreso se mostrará cada 10 steps\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 25:15, Epoch 300/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.673200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ENTRENAMIENTO COMPLETADO\n",
      "======================================================================\n",
      "Tiempo total: 25.3 minutos (0.42 horas)\n",
      "\n",
      "Guardando modelo fine-tuned...\n",
      "Modelo guardado en: modelo_finetuned/\n",
      "\n",
      "FINE-TUNING COMPLETADO EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# ENTRENAMIENTO - VERSIÓN CORREGIDA\n",
    "# =========================================================================\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREPARACIÓN DEL ENTRENAMIENTO\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Cargar dataset\n",
    "dataset = load_dataset('json', data_files={\n",
    "    'train': 'fine_tuning_data/dataset_train.json',\n",
    "    'test': 'fine_tuning_data/dataset_val.json'\n",
    "})\n",
    "\n",
    "print(f\"Train: {len(dataset['train'])} ejemplos\")\n",
    "print(f\"Validation: {len(dataset['test'])} ejemplos\\n\")\n",
    "\n",
    "# Función de formato - DEBE RETORNAR LISTA\n",
    "def formatting_func(example):\n",
    "    output = []\n",
    "    text = f\"\"\"### Instrucción:\n",
    "{example['instruction']}\n",
    "\n",
    "### Entrada:\n",
    "{example['input']}\n",
    "\n",
    "### Respuesta:\n",
    "{example['output']}\"\"\"\n",
    "    output.append(text)\n",
    "    return output\n",
    "\n",
    "# Configuración\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs_finetuning\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    max_steps=300,\n",
    "    warmup_steps=10,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    fp16=True,\n",
    "    save_strategy=\"steps\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=2048,\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INICIANDO ENTRENAMIENTO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nConfiguración:\")\n",
    "print(f\"  Batch size efectivo: 8\")\n",
    "print(f\"  Max steps: 300\")\n",
    "print(f\"  Learning rate: 2e-4\")\n",
    "print(f\"\\nTiempo estimado: 45-60 minutos con TinyLlama\")\n",
    "print(\"El progreso se mostrará cada 10 steps\\n\")\n",
    "\n",
    "# Entrenar\n",
    "inicio = time.time()\n",
    "trainer.train()\n",
    "tiempo_total = (time.time() - inicio) / 60\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Tiempo total: {tiempo_total:.1f} minutos ({tiempo_total/60:.2f} horas)\")\n",
    "\n",
    "# Guardar\n",
    "print(\"\\nGuardando modelo fine-tuned...\")\n",
    "model.save_pretrained(\"modelo_finetuned\")\n",
    "tokenizer.save_pretrained(\"modelo_finetuned\")\n",
    "\n",
    "print(\"Modelo guardado en: modelo_finetuned/\")\n",
    "print(\"\\nFINE-TUNING COMPLETADO EXITOSAMENTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf68b9a-2ab9-4685-8d0e-88a183420dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CARGANDO MODELO FINE-TUNED\n",
      "======================================================================\n",
      "\n",
      "Modelo cargado\n",
      "\n",
      "======================================================================\n",
      "PRUEBA 1: EXTRACCIÓN DE INFORMACIÓN\n",
      "======================================================================\n",
      "\n",
      "Tempo: 0.2 s\n",
      "Interpretación:\n",
      "\n",
      "Fecha: 15 de diciembre del 2024.\n",
      "\n",
      "Elemento: Disolución.\n",
      "\n",
      "Tipo: Remate.\n",
      "\n",
      "======================================================================\n",
      "PRUEBA 2: FORMATEO PROFESIONAL\n",
      "======================================================================\n",
      "\n",
      "AVISO DE ESTADO CORRE INTERIOR - CONDICIONES Y FINES SUPERVISORIO N° 1-2588846-2025\n",
      "\n",
      "AVISO DE ESTADO CORRE INTERIOR - CONDICIONES Y FINES SUPERVISORIO N° 1-2588846-2025\n",
      "\n",
      "### Ficha de intervención:\n",
      "Intervención en nombre de:\n",
      "- Ejecutor Coactivo: Address: RUC N° 20123456789, N° 1, E.I.D.N.A.N.A. De LGS, E.I.D.N.A.N.A. De LGS, D.N.I. 201234567\n",
      "\n",
      "======================================================================\n",
      "MODELO FUNCIONANDO CORRECTAMENTE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# PRUEBA DEL MODELO FINE-TUNED\n",
    "# =========================================================================\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CARGANDO MODELO FINE-TUNED\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Cargar modelo y tokenizer\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(\n",
    "    \"modelo_finetuned\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer_ft = AutoTokenizer.from_pretrained(\"modelo_finetuned\")\n",
    "\n",
    "print(\"Modelo cargado\\n\")\n",
    "\n",
    "# Función para probar\n",
    "def probar_modelo(instruccion, input_text=\"\"):\n",
    "    prompt = f\"\"\"### Instrucción:\n",
    "{instruccion}\n",
    "\n",
    "### Entrada:\n",
    "{input_text}\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer_ft(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model_ft.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer_ft.eos_token_id\n",
    "    )\n",
    "    \n",
    "    respuesta = tokenizer_ft.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extraer solo la respuesta (después de \"### Respuesta:\")\n",
    "    respuesta = respuesta.split(\"### Respuesta:\")[-1].strip()\n",
    "    \n",
    "    return respuesta\n",
    "\n",
    "# PRUEBA 1: Extracción de información\n",
    "print(\"=\"*70)\n",
    "print(\"PRUEBA 1: EXTRACCIÓN DE INFORMACIÓN\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "texto_prueba = \"\"\"\n",
    "DISOLUCION Y LIQUIDACION\n",
    "SERVICIOS GENERALES LIMA S.A.C.\n",
    "RUC: 20512345678\n",
    "Fecha de publicación: 15/12/2024\n",
    "\"\"\"\n",
    "\n",
    "resultado = probar_modelo(\n",
    "    \"Extrae la información estructurada del siguiente aviso legal de disolución.\",\n",
    "    texto_prueba\n",
    ")\n",
    "\n",
    "print(resultado)\n",
    "\n",
    "# PRUEBA 2: Formateo\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRUEBA 2: FORMATEO PROFESIONAL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "resultado2 = probar_modelo(\n",
    "    \"Formatea la siguiente información en un aviso legal profesional.\",\n",
    "    \"Empresa ABC S.A., RUC 20123456789, disuelta el 10/01/2025\"\n",
    ")\n",
    "\n",
    "print(resultado2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODELO FUNCIONANDO CORRECTAMENTE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562c15b5-e3f4-4357-829f-f367442f6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRUEBA CON PARÁMETROS MEJORADOS\n",
      "======================================================================\n",
      "\n",
      "Pregunta: ¿Cuál es el nombre de la empresa?\n",
      "Respuesta: EXTRENIA EL NOMBRAMIENTO DE LA EMBEDDED DATA LIST EN LA QUE SE REALIZÓ LA EXPORTACIÓN.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# PRUEBA MEJORADA - PARÁMETROS OPTIMIZADOS\n",
    "# =========================================================================\n",
    "\n",
    "def probar_modelo_mejorado(instruccion, input_text=\"\"):\n",
    "    prompt = f\"\"\"### Instrucción:\n",
    "{instruccion}\n",
    "\n",
    "### Entrada:\n",
    "{input_text}\n",
    "\n",
    "### Respuesta:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer_ft(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model_ft.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.3,  # Más bajo = más conservador\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer_ft.eos_token_id\n",
    "    )\n",
    "    \n",
    "    respuesta = tokenizer_ft.decode(outputs[0], skip_special_tokens=True)\n",
    "    respuesta = respuesta.split(\"### Respuesta:\")[-1].strip()\n",
    "    \n",
    "    return respuesta\n",
    "\n",
    "# PRUEBA SIMPLE\n",
    "print(\"=\"*70)\n",
    "print(\"PRUEBA CON PARÁMETROS MEJORADOS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "texto = \"\"\"DISOLUCION\n",
    "EMPRESA: ABC SERVICIOS S.A.C.\n",
    "RUC: 20512345678\n",
    "FECHA: 15/12/2024\"\"\"\n",
    "\n",
    "resultado = probar_modelo_mejorado(\n",
    "    \"Extrae el nombre de la empresa del siguiente aviso de disolución.\",\n",
    "    texto\n",
    ")\n",
    "\n",
    "print(\"Pregunta: ¿Cuál es el nombre de la empresa?\")\n",
    "print(f\"Respuesta: {resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37d3fc-d535-4d73-b57c-3f24383b2aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (FT Final)",
   "language": "python",
   "name": "ft_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
