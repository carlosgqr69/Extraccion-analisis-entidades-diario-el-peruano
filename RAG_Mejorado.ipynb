{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db34670c-730c-49f1-ac7f-fdfbec50e061",
   "metadata": {},
   "source": [
    "1. IMPORTS Y CONFIG. MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a42cf4-c661-418e-bff4-82eae91f27b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0110 15:17:38.528000 9072 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Carlos\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Imports configurados\n",
      "Metodología basada en: Rangan & Yin (2024) - RAG + Fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# RAG MEJORADO - Corrección de datos y optimización\n",
    "# Basado en: \"A fine-tuning enhanced RAG system\" (Rangan & Yin)\n",
    "# =========================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "import re\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from llama_index.core import Document, VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# Configurar modelos\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "Settings.llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    request_timeout=120.0,\n",
    "    system_prompt=(\n",
    "        \"Eres un asistente experto en documentos legales peruanos. \"\n",
    "        \"SIEMPRE respondes en español. \"\n",
    "        \"Usas únicamente la información proporcionada. \"\n",
    "        \"Nunca inventes información.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Imports configurados\")\n",
    "print(\"Metodología basada en: Rangan & Yin (2024) - RAG + Fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72a863-acbf-4008-8778-577a47ddf0ff",
   "metadata": {},
   "source": [
    "2. CARGA Y MEJORA DE CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68531d-ca7c-4ff7-b679-32ba1eb973cf",
   "metadata": {},
   "source": [
    "\" Al Intentar extracción estructurada con regex (17.9% éxito) detectamos limitaciones. Identificamos que el 82% de los registros tenían información fragmentada que no permitía extracción estructurada con regex. Implementamos un enfoque donde el LLM extrae directamente del texto completo, que es más robusto y la técnica es respaldada por papers recientes (Rangan & Yin, 2024).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc83974a-4d09-464f-8689-46657d83db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CARGANDO CSV ORIGINAL\n",
      "======================================================================\n",
      "\n",
      "Total registros: 3,060,033\n",
      "Registros relevantes: 17,008\n",
      "\n",
      "Distribución por tipo:\n",
      "tipo\n",
      "REMATE               9515\n",
      "JUNTA_ACCIONISTAS    3804\n",
      "DISOLUCION           3689\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "EXTRAYENDO EMPRESAS DEL TEXTO COMPLETO\n",
      "======================================================================\n",
      "\n",
      "Extrayendo... (2-3 minutos)\n",
      "\n",
      "Completado en 0.8 segundos\n",
      "\n",
      "Resultados:\n",
      "  Total: 17,008\n",
      "  Extraídas: 3,047 (17.9%)\n",
      "  No extraídas: 13,961\n",
      "\n",
      "Desglose por tipo:\n",
      "  JUNTA_ACCIONISTAS: 1393/3804 (36.6%)\n",
      "  DISOLUCION: 370/3689 (10.0%)\n",
      "  REMATE: 1284/9515 (13.5%)\n",
      "\n",
      "Guardando CSV mejorado...\n",
      "Guardado: base_datos_completa_mejorada.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CARGAR Y MEJORAR CSV\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CARGANDO CSV ORIGINAL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Cargar CSV actual\n",
    "df = pd.read_csv(\"base_datos_final/base_datos_completa.csv\", low_memory=False)\n",
    "print(f\"Total registros: {len(df):,}\")\n",
    "\n",
    "# Filtrar tipos relevantes\n",
    "tipos_relevantes = ['JUNTA_ACCIONISTAS', 'DISOLUCION', 'REMATE']\n",
    "df_filtrado = df[df['tipo'].isin(tipos_relevantes)].copy()\n",
    "print(f\"Registros relevantes: {len(df_filtrado):,}\\n\")\n",
    "\n",
    "print(\"Distribución por tipo:\")\n",
    "print(df_filtrado['tipo'].value_counts())\n",
    "\n",
    "# APLICAR EXTRACCIÓN DE EMPRESAS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRAYENDO EMPRESAS DEL TEXTO COMPLETO\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def extraer_empresa_del_texto(texto, tipo):\n",
    "    \"\"\"\n",
    "    Extrae nombre real usando regex\n",
    "    \"\"\"\n",
    "    if not isinstance(texto, str) or len(texto) < 20:\n",
    "        return None\n",
    "    \n",
    "    texto = texto.replace('\\n', ' ')\n",
    "    \n",
    "    if tipo == 'DISOLUCION':\n",
    "        patrones = [\n",
    "            r'disolución\\s+y\\s+liquidación\\s+de\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))',\n",
    "            r'empresa\\s+denominada\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))',\n",
    "            r'sociedad\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))',\n",
    "            r'de\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))\\s+con\\s+RUC',\n",
    "        ]\n",
    "    elif tipo == 'JUNTA_ACCIONISTAS':\n",
    "        patrones = [\n",
    "            r'junta\\s+.*?de\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))',\n",
    "            r'empresa\\s+([A-Z][A-ZÁÉÍÓÚÑa-záéíóúñ\\s\\.\\-&]+?(?:S\\.A\\.C\\.|S\\.A\\.|E\\.I\\.R\\.L\\.|S\\.R\\.L\\.))',\n",
    "        ]\n",
    "    elif tipo == 'REMATE':\n",
    "        patrones = [\n",
    "            r'ubicado\\s+en\\s+([^,\\.]{10,100})',\n",
    "            r'ubicación[:\\s]+([^,\\.]{10,100})',\n",
    "            r'inmueble\\s+sito\\s+en\\s+([^,\\.]{10,100})',\n",
    "        ]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto, re.IGNORECASE)\n",
    "        if match:\n",
    "            nombre = match.group(1).strip()\n",
    "            nombre = re.sub(r'\\s+', ' ', nombre)\n",
    "            \n",
    "            if 5 < len(nombre) < 150:\n",
    "                if not nombre.upper().startswith(('DISOLUCION', 'LIQUIDACION', 'JUNTA', 'AVISO')):\n",
    "                    return nombre\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"Extrayendo... (2-3 minutos)\")\n",
    "inicio = time.time()\n",
    "\n",
    "df_filtrado['empresa_extraida'] = df_filtrado.apply(\n",
    "    lambda row: extraer_empresa_del_texto(row['texto_completo'], row['tipo']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "tiempo = time.time() - inicio\n",
    "\n",
    "# Estadísticas\n",
    "extraidas = df_filtrado['empresa_extraida'].notna().sum()\n",
    "porcentaje = (extraidas / len(df_filtrado)) * 100\n",
    "\n",
    "print(f\"\\nCompletado en {tiempo:.1f} segundos\")\n",
    "print(f\"\\nResultados:\")\n",
    "print(f\"  Total: {len(df_filtrado):,}\")\n",
    "print(f\"  Extraídas: {extraidas:,} ({porcentaje:.1f}%)\")\n",
    "print(f\"  No extraídas: {len(df_filtrado) - extraidas:,}\")\n",
    "\n",
    "print(\"\\nDesglose por tipo:\")\n",
    "for tipo in tipos_relevantes:\n",
    "    df_tipo = df_filtrado[df_filtrado['tipo'] == tipo]\n",
    "    ext = df_tipo['empresa_extraida'].notna().sum()\n",
    "    print(f\"  {tipo}: {ext}/{len(df_tipo)} ({ext/len(df_tipo)*100:.1f}%)\")\n",
    "\n",
    "# Guardar CSV mejorado\n",
    "print(\"\\nGuardando CSV mejorado...\")\n",
    "df_filtrado.to_csv(\"base_datos_final/base_datos_completa_mejorada.csv\", index=False)\n",
    "print(\"Guardado: base_datos_completa_mejorada.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03472a72-038f-4b57-a416-4782783b995d",
   "metadata": {},
   "source": [
    "3. RAG CON TEXTO COMPLETO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b6076b-eb3b-4db4-a8cc-da03aa0b158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREANDO RAG CON TEXTO COMPLETO\n",
      "Estrategia: Dejar que el LLM extraiga del texto\n",
      "======================================================================\n",
      "\n",
      "17,008 documentos creados\n",
      "\n",
      "Creando chunks (tamaño 800)...\n",
      "17,008 chunks creados\n",
      "\n",
      "Creando base de datos vectorial...\n",
      "Creando índice vectorial (5-10 min)...\n",
      "\n",
      "\n",
      "17,008 vectores creados en 4.8 minutos\n",
      "Base de datos guardada en: rag_database_final/\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# SOLUCIÓN: RAG CON TEXTO COMPLETO (SIN EXTRAER EMPRESA)\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREANDO RAG CON TEXTO COMPLETO\")\n",
    "print(\"Estrategia: Dejar que el LLM extraiga del texto\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "documents_final = []\n",
    "\n",
    "for idx, row in df_filtrado.iterrows():\n",
    "    # Usar texto completo directamente (1500 caracteres)\n",
    "    texto = str(row.get('texto_completo', ''))[:1500]\n",
    "    \n",
    "    # Metadata SOLO con tipo, mes, año (sin empresa)\n",
    "    mes_val = row.get('mes', '')\n",
    "    año_val = row.get('año', '')\n",
    "    \n",
    "    doc = Document(\n",
    "        text=texto,\n",
    "        metadata={\n",
    "            'tipo': str(row.get('tipo', '')),\n",
    "            'fecha': str(row.get('fecha', '')),\n",
    "            'año': str(int(año_val)) if pd.notna(año_val) else '',\n",
    "            'mes': str(int(mes_val)).zfill(2) if pd.notna(mes_val) else '',\n",
    "            'id_registro': idx\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    documents_final.append(doc)\n",
    "\n",
    "print(f\"{len(documents_final):,} documentos creados\\n\")\n",
    "\n",
    "# Chunks más grandes (para mantener contexto)\n",
    "print(\"Creando chunks (tamaño 800)...\")\n",
    "parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "nodes_final = parser.get_nodes_from_documents(documents_final)\n",
    "print(f\"{len(nodes_final):,} chunks creados\\n\")\n",
    "\n",
    "# ChromaDB\n",
    "print(\"Creando base de datos vectorial...\")\n",
    "PERSIST_DIR_FINAL = Path(\"rag_database_final\")\n",
    "PERSIST_DIR_FINAL.mkdir(exist_ok=True)\n",
    "\n",
    "chroma_client_final = chromadb.PersistentClient(path=str(PERSIST_DIR_FINAL))\n",
    "\n",
    "try:\n",
    "    chroma_client_final.delete_collection(\"diario_final\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "chroma_collection_final = chroma_client_final.create_collection(\n",
    "    name=\"diario_final\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "vector_store_final = ChromaVectorStore(chroma_collection=chroma_collection_final)\n",
    "storage_context_final = StorageContext.from_defaults(vector_store=vector_store_final)\n",
    "\n",
    "print(\"Creando índice vectorial (5-10 min)...\\n\")\n",
    "inicio = time.time()\n",
    "index_final = VectorStoreIndex(nodes_final, storage_context=storage_context_final)\n",
    "tiempo = time.time() - inicio\n",
    "\n",
    "print(f\"\\n{chroma_collection_final.count():,} vectores creados en {tiempo/60:.1f} minutos\")\n",
    "print(\"Base de datos guardada en: rag_database_final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5067982-4274-4ec7-a6f0-bb76e6af3f52",
   "metadata": {},
   "source": [
    "4. FUNCIÓN DE CONSULTA FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3806e8d3-f7b9-4875-adcb-350c85e2e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función consultar_rag_final() lista\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# FUNCIÓN DE CONSULTA FINAL\n",
    "# =========================================================================\n",
    "\n",
    "def consultar_rag_final(pregunta, tipo=None, mes=None, año='2025', top_k=15, verbose=True):\n",
    "    \"\"\"\n",
    "    RAG final: El LLM extrae información del texto completo\n",
    "    \"\"\"\n",
    "    inicio = time.time()\n",
    "    \n",
    "    if mes:\n",
    "        mes = str(mes).zfill(2)\n",
    "    \n",
    "    # Filtros\n",
    "    filters_list = []\n",
    "    if tipo:\n",
    "        filters_list.append(ExactMatchFilter(key=\"tipo\", value=tipo))\n",
    "    if mes:\n",
    "        filters_list.append(ExactMatchFilter(key=\"mes\", value=mes))\n",
    "    if año:\n",
    "        filters_list.append(ExactMatchFilter(key=\"año\", value=año))\n",
    "    \n",
    "    # Retriever\n",
    "    if filters_list:\n",
    "        filters = MetadataFilters(filters=filters_list)\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=index_final,\n",
    "            similarity_top_k=top_k,\n",
    "            filters=filters\n",
    "        )\n",
    "    else:\n",
    "        retriever = VectorIndexRetriever(index=index_final, similarity_top_k=top_k)\n",
    "    \n",
    "    # Recuperar\n",
    "    nodes = retriever.retrieve(pregunta)\n",
    "    \n",
    "    # Reranking\n",
    "    for node in nodes:\n",
    "        bonus = 0\n",
    "        if tipo and node.metadata.get('tipo') == tipo:\n",
    "            bonus += 0.2\n",
    "        if mes and node.metadata.get('mes') == mes:\n",
    "            bonus += 0.2\n",
    "        node.score = node.score * 0.6 + bonus\n",
    "    \n",
    "    # Top 8 después de reranking\n",
    "    nodes = sorted(nodes, key=lambda x: x.score, reverse=True)[:8]\n",
    "    \n",
    "    # Prompt optimizado\n",
    "    qa_prompt = PromptTemplate(\n",
    "        \"A continuación tienes documentos legales del Diario Oficial El Peruano.\\n\\n\"\n",
    "        \"DOCUMENTOS:\\n{context_str}\\n\\n\"\n",
    "        \"INSTRUCCIONES:\\n\"\n",
    "        \"- Lee cuidadosamente cada documento\\n\"\n",
    "        \"- Extrae: nombre COMPLETO de la empresa (con sufijo legal S.A.C., E.I.R.L., S.A., S.R.L.), RUC, fecha\\n\"\n",
    "        \"- Lista TODAS las empresas que encuentres\\n\"\n",
    "        \"- Si un documento no tiene empresa clara, omítelo\\n\"\n",
    "        \"- NO inventes información\\n\"\n",
    "        \"- Formato: Empresa completa, RUC, Fecha\\n\\n\"\n",
    "        \"PREGUNTA: {query_str}\\n\\n\"\n",
    "        \"RESPUESTA:\"\n",
    "    )\n",
    "    \n",
    "    context = \"\\n\\n---DOCUMENTO---\\n\\n\".join([node.text for node in nodes])\n",
    "    \n",
    "    # Generar\n",
    "    llm_inicio = time.time()\n",
    "    response = Settings.llm.complete(\n",
    "        qa_prompt.format(context_str=context, query_str=pregunta)\n",
    "    )\n",
    "    llm_tiempo = time.time() - llm_inicio\n",
    "    \n",
    "    tiempo_total = time.time() - inicio\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nMÉTRICAS:\")\n",
    "        print(f\"  Documentos recuperados: {len(nodes)}\")\n",
    "        print(f\"  Tiempo total: {tiempo_total:.1f}s\")\n",
    "        print(f\"  Tiempo LLM: {llm_tiempo:.1f}s\")\n",
    "        print(f\"  Score promedio: {sum(n.score for n in nodes)/len(nodes):.3f}\")\n",
    "    \n",
    "    return response.text, nodes, tiempo_total\n",
    "\n",
    "print(\"Función consultar_rag_final() lista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71274aba-fb6e-4526-a9ea-4a1e49f4bde5",
   "metadata": {},
   "source": [
    "5. PRUEBA FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b6cc9c-278f-416f-93a2-c28ab9578aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRUEBA: RAG FINAL (LLM extrae del texto)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "MÉTRICAS:\n",
      "  Documentos recuperados: 8\n",
      "  Tiempo total: 24.4s\n",
      "  Tiempo LLM: 24.3s\n",
      "  Score promedio: 0.821\n",
      "\n",
      "RESPUESTA DEL LLM:\n",
      "Basándome en los documentos legales del Diario Oficial El Peruano, puedo extraer la siguiente información:\n",
      "\n",
      "* NORDES SISTEMAS SAC, con RUC 20552001576, Fecha: no especificada (pero se refiere a abril de 2025)\n",
      "* Reestructuradora de Empresas S.A., sin fecha específica\n",
      "* Consultorías y Reestructuraciones Fénix S.A.C., con fecha 8 de abril del 2025\n",
      "\n",
      "Por lo tanto, las empresas que fueron disueltas en abril de 2025 son:\n",
      "\n",
      "1. NORDES SISTEMAS SAC, con RUC 20552001576\n",
      "2. Consultorías y Reestructuraciones Fénix S.A.C.\n",
      "\n",
      "Notar que Reestructuradora de Empresas S.A. no tiene fecha específica para la disolución, por lo que no puedo incluir esa empresa en la lista.\n",
      "\n",
      "======================================================================\n",
      "DOCUMENTOS RECUPERADOS (primeros 5)\n",
      "======================================================================\n",
      "\n",
      "1. Score: 0.825\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-04-20\n",
      "   Texto (150 chars): DISOLUCIÓN Y LIQUIDACIÓN Se comunica que mediante acuerdo de Junta Universal de Accionistas de Reestructuradora de Empresas S.A. de fecha 8 de abril d...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.824\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-04-16\n",
      "   Texto (150 chars): DISOLUCION DE EMPRESA Y NOMBRAMIENTO 2025, se acordó la...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.823\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-04-04\n",
      "   Texto (150 chars): DISOLUCIÓN Y LIQUIDACIÓN DE EMPRESA NACIONAL En la...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "4. Score: 0.819\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-04-19\n",
      "   Texto (150 chars): DISOLUCIÓN Y LIQUIDACIÓN Reestructuradora de Empresas S.A. de conocimiento público que la...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "5. Score: 0.819\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-04-13\n",
      "   Texto (150 chars): DISOLUCIÓN Y LIQUIDACIÓN Por acuerdo de los accionistas, del 04 de abril de 2025, En cumplimiento y para los fines establecidos en En cumplimiento y p...\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# PRUEBA FINAL\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRUEBA: RAG FINAL (LLM extrae del texto)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "respuesta, nodes, tiempo = consultar_rag_final(\n",
    "    \"¿Qué empresas fueron disueltas en abril 2025?\",\n",
    "    tipo='DISOLUCION',\n",
    "    mes='04',\n",
    "    año='2025'\n",
    ")\n",
    "\n",
    "print(f\"\\nRESPUESTA DEL LLM:\\n{respuesta}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DOCUMENTOS RECUPERADOS (primeros 5)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, node in enumerate(nodes[:5], 1):\n",
    "    print(f\"\\n{i}. Score: {node.score:.3f}\")\n",
    "    print(f\"   Tipo: {node.metadata.get('tipo')}\")\n",
    "    print(f\"   Fecha: {node.metadata.get('fecha')}\")\n",
    "    print(f\"   Texto (150 chars): {node.text[:150]}...\")\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2b6af-f482-46d1-a135-e17542133fe9",
   "metadata": {},
   "source": [
    "6. EVALUACIÓN FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc28e211-53e0-4b20-8cf6-cd5e14e5ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUACIÓN CUANTITATIVA - RAG FINAL\n",
      "======================================================================\n",
      "\n",
      "Queries evaluadas: 6\n",
      "\n",
      "RESULTADOS:\n",
      "  Precision tipo: 100.0%\n",
      "  Precision mes: 100.0%\n",
      "  Empresas promedio por respuesta: 7.2\n",
      "  Tiempo promedio: 38.4s\n",
      "\n",
      "Desglose:\n",
      "                                 query               tipo  precision_tipo  \\\n",
      "0  ¿Qué empresas fueron disueltas en a         DISOLUCION             1.0   \n",
      "1  ¿Qué empresas fueron disueltas en m         DISOLUCION             1.0   \n",
      "2                 Remates en mayo 2025             REMATE             1.0   \n",
      "3                Remates en junio 2025             REMATE             1.0   \n",
      "4  Juntas de accionistas en abril 2025  JUNTA_ACCIONISTAS             1.0   \n",
      "5  Juntas de accionistas en junio 2025  JUNTA_ACCIONISTAS             1.0   \n",
      "\n",
      "   precision_mes  empresas_aprox     tiempo  \n",
      "0            1.0               3  20.015801  \n",
      "1            1.0               8  32.267724  \n",
      "2            1.0               5  30.081078  \n",
      "3            1.0               0  64.962674  \n",
      "4            1.0              10  30.357054  \n",
      "5            1.0              17  52.632286  \n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# EVALUACIÓN FINAL\n",
    "# =========================================================================\n",
    "\n",
    "def evaluar_rag_final():\n",
    "    print(\"=\"*70)\n",
    "    print(\"EVALUACIÓN CUANTITATIVA - RAG FINAL\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    test_queries = [\n",
    "        (\"¿Qué empresas fueron disueltas en abril 2025?\", \"DISOLUCION\", \"04\"),\n",
    "        (\"¿Qué empresas fueron disueltas en mayo 2025?\", \"DISOLUCION\", \"05\"),\n",
    "        (\"Remates en mayo 2025\", \"REMATE\", \"05\"),\n",
    "        (\"Remates en junio 2025\", \"REMATE\", \"06\"),\n",
    "        (\"Juntas de accionistas en abril 2025\", \"JUNTA_ACCIONISTAS\", \"04\"),\n",
    "        (\"Juntas de accionistas en junio 2025\", \"JUNTA_ACCIONISTAS\", \"06\"),\n",
    "    ]\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for query, tipo, mes in test_queries:\n",
    "        respuesta, nodes, tiempo = consultar_rag_final(\n",
    "            query, tipo=tipo, mes=mes, verbose=False\n",
    "        )\n",
    "        \n",
    "        # Validar filtros\n",
    "        tipos_correctos = sum(1 for n in nodes if n.metadata.get('tipo') == tipo)\n",
    "        meses_correctos = sum(1 for n in nodes if n.metadata.get('mes') == mes)\n",
    "        \n",
    "        precision_tipo = tipos_correctos / len(nodes) if nodes else 0\n",
    "        precision_mes = meses_correctos / len(nodes) if nodes else 0\n",
    "        \n",
    "        # Contar empresas en la respuesta (aproximado)\n",
    "        empresas_mencionadas = respuesta.count('S.A.C.') + respuesta.count('E.I.R.L.') + respuesta.count('S.A.') + respuesta.count('S.R.L.')\n",
    "        \n",
    "        resultados.append({\n",
    "            'query': query[:35],\n",
    "            'tipo': tipo,\n",
    "            'precision_tipo': precision_tipo,\n",
    "            'precision_mes': precision_mes,\n",
    "            'empresas_aprox': empresas_mencionadas,\n",
    "            'tiempo': tiempo\n",
    "        })\n",
    "    \n",
    "    df_eval = pd.DataFrame(resultados)\n",
    "    \n",
    "    print(f\"Queries evaluadas: {len(df_eval)}\\n\")\n",
    "    print(\"RESULTADOS:\")\n",
    "    print(f\"  Precision tipo: {df_eval['precision_tipo'].mean():.1%}\")\n",
    "    print(f\"  Precision mes: {df_eval['precision_mes'].mean():.1%}\")\n",
    "    print(f\"  Empresas promedio por respuesta: {df_eval['empresas_aprox'].mean():.1f}\")\n",
    "    print(f\"  Tiempo promedio: {df_eval['tiempo'].mean():.1f}s\")\n",
    "    \n",
    "    print(\"\\nDesglose:\")\n",
    "    print(df_eval)\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "# Ejecutar\n",
    "df_eval_final = evaluar_rag_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e03c9-8880-40e3-99b3-ccdf186dba65",
   "metadata": {},
   "source": [
    "7. RESULTADOS FINALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9d0b62-16c1-484a-852c-bb574a5ee99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DOCUMENTACIÓN - RESULTADOS DEL RAG FINAL\n",
      "======================================================================\n",
      "\n",
      "\n",
      "# SISTEMA RAG - DIARIO EL PERUANO\n",
      "# Resultados Finales\n",
      "\n",
      "## 1. ARQUITECTURA IMPLEMENTADA\n",
      "\n",
      "- Embeddings: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "  * Dimensiones: 384\n",
      "  * Optimizado para español\n",
      "  * 118M parámetros\n",
      "\n",
      "- Vector Store: ChromaDB\n",
      "  * Algoritmo: HNSW (Hierarchical Navigable Small World)\n",
      "  * Métrica: Similitud coseno\n",
      "  * Vectores totales: 17,008\n",
      "  * Persistencia: Local (rag_database_final/)\n",
      "\n",
      "- LLM: Llama3-8B\n",
      "  * Deployment: Local via Ollama\n",
      "  * Uso: Generación y extracción de información\n",
      "  * Contexto: 8K tokens\n",
      "\n",
      "## 2. DATOS\n",
      "\n",
      "- Registros totales procesados: 3,060,033\n",
      "- Registros relevantes (3 tipos): 17,008\n",
      "  * Disoluciones: 3,689\n",
      "  * Remates: 9,515\n",
      "  * Juntas: 3,804\n",
      "\n",
      "- Periodo: Abril - Noviembre 2025 (8 meses)\n",
      "- Chunks creados: 17,008\n",
      "- Tamaño chunk: 800 tokens (overlap 100)\n",
      "\n",
      "## 3. ESTRATEGIA DE PROCESAMIENTO\n",
      "\n",
      "Inicial: Extracción estructurada con regex\n",
      "- Éxito: 17.9%\n",
      "- Problema: Textos mal formateados en CSV\n",
      "\n",
      "Final: Texto completo sin pre-extracción\n",
      "- El LLM extrae información del texto\n",
      "- Más robusto con datos reales\n",
      "- Approach respaldado por papers (Rangan & Yin, 2024)\n",
      "\n",
      "## 4. RECUPERACIÓN (RETRIEVAL)\n",
      "\n",
      "Proceso:\n",
      "1. Query → Embedding (384D)\n",
      "2. Búsqueda similitud en ChromaDB\n",
      "3. Filtros metadata (tipo, mes, año) - Exact match\n",
      "4. Reranking: 60% similitud + 40% metadata\n",
      "5. Top-K: 8 documentos finales\n",
      "\n",
      "## 5. MÉTRICAS DE EVALUACIÓN\n",
      "\n",
      "Queries evaluadas: 6\n",
      "Tipos evaluados: DISOLUCION, REMATE, JUNTA_ACCIONISTAS\n",
      "\n",
      "RESULTADOS:\n",
      "- Precision tipo: 100%\n",
      "- Precision mes: 100%\n",
      "- Empresas promedio por respuesta: 7.2\n",
      "- Tiempo promedio: 38.4s\n",
      "\n",
      "Desglose por tipo:\n",
      "                   precision_tipo  precision_mes\n",
      "tipo                                            \n",
      "DISOLUCION                    1.0            1.0\n",
      "JUNTA_ACCIONISTAS             1.0            1.0\n",
      "REMATE                        1.0            1.0\n",
      "\n",
      "## 6. VENTAJAS DEL SISTEMA\n",
      "\n",
      " 100% local (sin APIs de pago)\n",
      " Sin costos operativos\n",
      " Privacidad garantizada (datos no salen)\n",
      " Filtros metadata precisos (100%)\n",
      " Robusto con datos reales (con ruido)\n",
      " Escalable (millones de documentos)\n",
      " Verificable (citas a documentos fuente)\n",
      "\n",
      "## 7. LIMITACIONES IDENTIFICADAS\n",
      "\n",
      " Tiempo de respuesta: 30-65s (principalmente LLM)\n",
      " Calidad depende del texto original en PDFs\n",
      " Corpus limitado a 8 meses (expandible)\n",
      "\n",
      "## 8. PRÓXIMOS PASOS\n",
      "\n",
      " Fine-tuning de Llama3 para formateo de respuestas\n",
      " Optimización de velocidad (caching, streaming)\n",
      " Expansión del corpus (años anteriores)\n",
      " Interfaz web (Streamlit/Gradio)\n",
      "\n",
      "---\n",
      "Generado: 2026-01-10 16:42:10\n",
      "\n",
      "\n",
      " Documentación guardada: RESULTADOS_RAG_FINAL.txt\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CELDA 7: DOCUMENTAR RESULTADOS FINALES\n",
    "# =========================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DOCUMENTACIÓN - RESULTADOS DEL RAG FINAL\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "resultados_finales = f\"\"\"\n",
    "# SISTEMA RAG - DIARIO EL PERUANO\n",
    "# Resultados Finales\n",
    "\n",
    "## 1. ARQUITECTURA IMPLEMENTADA\n",
    "\n",
    "- Embeddings: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "  * Dimensiones: 384\n",
    "  * Optimizado para español\n",
    "  * 118M parámetros\n",
    "\n",
    "- Vector Store: ChromaDB\n",
    "  * Algoritmo: HNSW (Hierarchical Navigable Small World)\n",
    "  * Métrica: Similitud coseno\n",
    "  * Vectores totales: {chroma_collection_final.count():,}\n",
    "  * Persistencia: Local (rag_database_final/)\n",
    "\n",
    "- LLM: Llama3-8B\n",
    "  * Deployment: Local via Ollama\n",
    "  * Uso: Generación y extracción de información\n",
    "  * Contexto: 8K tokens\n",
    "\n",
    "## 2. DATOS\n",
    "\n",
    "- Registros totales procesados: {len(df):,}\n",
    "- Registros relevantes (3 tipos): {len(df_filtrado):,}\n",
    "  * Disoluciones: {len(df_filtrado[df_filtrado['tipo']=='DISOLUCION']):,}\n",
    "  * Remates: {len(df_filtrado[df_filtrado['tipo']=='REMATE']):,}\n",
    "  * Juntas: {len(df_filtrado[df_filtrado['tipo']=='JUNTA_ACCIONISTAS']):,}\n",
    "\n",
    "- Periodo: Abril - Noviembre 2025 (8 meses)\n",
    "- Chunks creados: {len(nodes_final):,}\n",
    "- Tamaño chunk: 800 tokens (overlap 100)\n",
    "\n",
    "## 3. ESTRATEGIA DE PROCESAMIENTO\n",
    "\n",
    "Inicial: Extracción estructurada con regex\n",
    "- Éxito: 17.9%\n",
    "- Problema: Textos mal formateados en CSV\n",
    "\n",
    "Final: Texto completo sin pre-extracción\n",
    "- El LLM extrae información del texto\n",
    "- Más robusto con datos reales\n",
    "- Approach respaldado por papers (Rangan & Yin, 2024)\n",
    "\n",
    "## 4. RECUPERACIÓN (RETRIEVAL)\n",
    "\n",
    "Proceso:\n",
    "1. Query → Embedding (384D)\n",
    "2. Búsqueda similitud en ChromaDB\n",
    "3. Filtros metadata (tipo, mes, año) - Exact match\n",
    "4. Reranking: 60% similitud + 40% metadata\n",
    "5. Top-K: 8 documentos finales\n",
    "\n",
    "## 5. MÉTRICAS DE EVALUACIÓN\n",
    "\n",
    "Queries evaluadas: 6\n",
    "Tipos evaluados: DISOLUCION, REMATE, JUNTA_ACCIONISTAS\n",
    "\n",
    "RESULTADOS:\n",
    "- Precision tipo: 100%\n",
    "- Precision mes: 100%\n",
    "- Empresas promedio por respuesta: 7.2\n",
    "- Tiempo promedio: 38.4s\n",
    "\n",
    "Desglose por tipo:\n",
    "{df_eval_final.groupby('tipo')[['precision_tipo', 'precision_mes']].mean().to_string()}\n",
    "\n",
    "## 6. VENTAJAS DEL SISTEMA\n",
    "\n",
    " 100% local (sin APIs de pago)\n",
    " Sin costos operativos\n",
    " Privacidad garantizada (datos no salen)\n",
    " Filtros metadata precisos (100%)\n",
    " Robusto con datos reales (con ruido)\n",
    " Escalable (millones de documentos)\n",
    " Verificable (citas a documentos fuente)\n",
    "\n",
    "## 7. LIMITACIONES IDENTIFICADAS\n",
    "\n",
    " Tiempo de respuesta: 30-65s (principalmente LLM)\n",
    " Calidad depende del texto original en PDFs\n",
    " Corpus limitado a 8 meses (expandible)\n",
    "\n",
    "## 8. PRÓXIMOS PASOS\n",
    "\n",
    " Fine-tuning de Llama3 para formateo de respuestas\n",
    " Optimización de velocidad (caching, streaming)\n",
    " Expansión del corpus (años anteriores)\n",
    " Interfaz web (Streamlit/Gradio)\n",
    "\n",
    "---\n",
    "Generado: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "print(resultados_finales)\n",
    "\n",
    "# Guardar documentación\n",
    "with open('RESULTADOS_RAG_FINAL.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(resultados_finales)\n",
    "\n",
    "print(\"\\n Documentación guardada: RESULTADOS_RAG_FINAL.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4869964-810f-4bae-8b89-328806cf399f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
