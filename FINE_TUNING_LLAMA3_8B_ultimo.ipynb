{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Saca el máximo partido de tu suscripción a Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_m4yNYDV4gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMXjkKUS73r3"
      },
      "source": [
        "# ¡Google Colab está disponible en VS Code!\n",
        "![logo.webp](data:image/webp;base64,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)\n",
        "\n",
        "Prueba la nueva <a href=\"https://marketplace.visualstudio.com/items?itemName=Google.colab\">extensión de Google Colab</a> para Visual Studio Code. Puedes empezar a usarla con solo unos clics:\n",
        "\n",
        "*  En VS Code, abre la vista <strong><em>Extensiones</em></strong> y busca \"Google Colab\" para instalarla.\n",
        "*  Para abrir el selector de kernels, crea o abre cualquier archivo de cuaderno <code>.ipynb</code> en tu espacio de trabajo local y ejecuta una celda o haz clic en el botón <strong><em>Seleccionar kernel</em></strong> situado arriba a la derecha.\n",
        "*  Haz clic en <strong><em>Colab</em></strong> y, a continuación, selecciona el entorno de ejecución que quieras, inicia sesión con tu cuenta de Google y ya estará todo listo.\n",
        "\n",
        "Consulta más información en <a href=\"https://developers.googleblog.com/google-colab-is-coming-to-vs-code\">esta entrada de nuestro blog</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjTLZD16HebW"
      },
      "source": [
        "# Access Popular LLMs via Google-Colab-AI Without an API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwVZpSEoHkQH"
      },
      "source": [
        "Users with Colab's paid plans have free access to most popular LLMs via google-colab-ai Python library. For more details, refer to the [getting started with google colab ai](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebl8tzi917TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71957975-d91a-4039-a2f1-a576f00292f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## GPU más rápidas\n",
        "\n",
        "<p>Los usuarios que hayan comprado uno de los planes de pago de Colab tendrán acceso a GPUs más rápidas y a más memoria. Puedes cambiar los ajustes de tu cuaderno para usar una GPU superior accediendo al menú <code>Entorno de ejecución &gt; Cambiar tipo de entorno de ejecución</code> y seleccionando entre varias opciones de acelerador, sujetas a disponibilidad.</p>\n",
        "<p>La versión sin coste económico de Colab ofrece acceso a GPUs T4 de Nvidia sujeto a restricciones de cuota y de disponibilidad.</p>\n",
        "\n",
        "Si quieres ver qué GPU te han asignado en cualquier momento, ejecuta la siguiente celda. Si el resultado de la ejecución de la celda de código que aparece más abajo es \"Not connected to a GPU\", puedes cambiar el entorno de ejecución. Para ello, ve al menú <code>Entorno de ejecución &gt; Cambiar tipo de entorno de ejecución</code>, habilita el acelerador de GPU y, después, vuelve a ejecutar la celda de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "627b1d0e-2bba-49c3-c363-486bd7212af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 12 20:07:10 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             49W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "Para poder usar una GPU con tu cuaderno, selecciona el menú <code>Entorno de ejecución &gt; Cambiar tipo de entorno de ejecución</code> y, a continuación, configura la aceleración por hardware en la opción que quieras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## Más memoria\n",
        "\n",
        "Los usuarios que hayan comprado uno de los planes de pago de Colab tendrán acceso a VMs con alta capacidad de memoria cuando estén disponibles. Las GPUs más potentes siempre se ofrecen con VMs de gran capacidad de memoria.\n",
        "Si quieres ver cuánta memoria hay disponible en cualquier momento, ejecuta la siguiente celda de código. Si el resultado de la ejecución de la celda de código que aparece más abajo es \"Not using a high-RAM runtime\", puedes habilitar un entorno de ejecución de alta capacidad de RAM. Para ello, accede al menú <code>Entorno de ejecución &gt; Cambiar tipo de entorno de ejecución</code>. Luego, selecciona Alta capacidad de RAM en el botón activar/desactivar Características del entorno de ejecución. A continuación, vuelve a ejecutar la celda de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1G82GuO-tez",
        "outputId": "f27e303a-2ce2-4b3e-8427-1d9a822dc10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Tiempos de ejecución más largos\n",
        "\n",
        "Todos los entornos de ejecución de Colab se restablecen tras un periodo concreto, que es más breve si el entorno no está ejecutando ningún código. Los usuarios de Colab Pro y Pro+ tienen acceso a tiempos de ejecución más largos que los usuarios de la versión sin coste económico de Colab.\n",
        "\n",
        "## Ejecución en segundo plano\n",
        "\n",
        "Los usuarios de Colab Pro+ tienen acceso a la ejecución en segundo plano: al usarla, los cuadernos se seguirán ejecutando, incluso después de que hayas cerrado una pestaña del navegador. Esta función siempre se habilita en los entornos de ejecución Pro+ mientras que tengas unidades de computación disponibles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Disfruta de unos límites de recursos más laxos con Colab Pro\n",
        "\n",
        "Los recursos que te ofrece Colab no son ilimitados. Para sacar el máximo partido a Colab, evita usar recursos cuando no los necesites. Por ejemplo, utiliza una GPU solo cuando sea necesario y cierra las pestañas de Colab cuando termines de usarlas.\n",
        "\n",
        "Si experimentas limitaciones de uso, puedes hacer que sean más laxas comprando más unidades informáticas con el modelo de pago por uso. Cualquier persona puede comprar unidades informáticas con el modelo de <a href=\"https://colab.research.google.com/signup\">pago por uso</a>, no es necesario tener ninguna suscripción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Danos tu opinión\n",
        "\n",
        "<p>Si tienes algún comentario, ponte en contacto con nosotros. La mejor forma de enviar tus comentarios es mediante el menú Ayuda &gt; Enviar comentarios. Si experimentas límites de uso en Colab Pro, puede que te interese suscribirte a Colab Pro+.</p>\n",
        "<p>Si surgen errores u otros problemas relacionados con la facturación &#40;pagos&#41; de Colab Pro o Pro+, o con el modelo de pago por uso, envía un correo a <a href=\"mailto:colab-billing@google.com\">colab-billing@google.com</a>.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## Más recursos\n",
        "\n",
        "### Trabajar con cuadernos en Colab\n",
        "- [Introducción a Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guía de Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importar bibliotecas e instalar dependencias](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Guardar y cargar cuadernos en GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Formularios interactivos](/notebooks/forms.ipynb)\n",
        "- [Widgets interactivos](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Trabajar con datos\n",
        "- [Cargar datos: Drive, Hojas de cálculo y Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Gráficos: visualización de datos](/notebooks/charts.ipynb)\n",
        "- [Primeros pasos con BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Curso intensivo de aprendizaje automático\n",
        "A continuación, se muestran algunos cuadernos del curso online de Google sobre aprendizaje automático. Para obtener más información, consulta el <a href=\"https://developers.google.com/machine-learning/crash-course/\">sitio web del curso completo</a>.\n",
        "- [Introducción a Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Regresión lineal con tf.keras usando datos sintéticos](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Uso de hardware acelerado\n",
        "- [TensorFlow con GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs en Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Ejemplos de aprendizaje automático\n",
        "\n",
        "Si quieres ver ejemplos completos de los análisis interactivos de aprendizaje automático que se pueden llevar a cabo con Colab, consulta los tutoriales desarrollados con modelos en <a href=\"https://tfhub.dev\">TensorFlow Hub</a>.\n",
        "\n",
        "A continuación se indican algunos ejemplos destacados:\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">Reentrenamiento de un clasificador de imágenes</a>: crea un modelo de Keras sobre un clasificador de imágenes preparado previamente para que distinga flores.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">Clasificación de textos</a>: clasifica las reseñas de películas de IMDb en <em>positivas</em> o <em>negativas</em>.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">Transferencia de estilo</a>: utiliza el aprendizaje profundo para transferir el estilo de una imagen a otra.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">Codificador universal de frases multilingüe para preguntas y respuestas</a>: utiliza un modelo de aprendizaje automático para contestar preguntas con el conjunto de datos SQuAD.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">Interpolación de vídeo</a>: predice lo que ocurre entre el primer y el último fotograma de un vídeo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Instalando versiones específicas...\")\n",
        "!pip uninstall -y trl\n",
        "!pip install trl==0.8.6 -q\n",
        "print(\"Instalado. IMPORTANTE: Runtime → Restart runtime\")"
      ],
      "metadata": {
        "id": "-O58ky9a0Vsf",
        "outputId": "8ee249d8-9025-4efc-b329-87d58fe09564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando versiones específicas...\n",
            "Found existing installation: trl 0.8.6\n",
            "Uninstalling trl-0.8.6:\n",
            "  Successfully uninstalled trl-0.8.6\n",
            "Instalado. IMPORTANTE: Runtime → Restart runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# FINE-TUNING LLAMA3-8B - TRL 0.8.6\n",
        "# =========================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINE-TUNING LLAMA3-8B\")\n",
        "print(\"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "id": "PbCDPp5l0k_w",
        "outputId": "ceab1644-31a4-411b-a61c-de6c4d5b5ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FINE-TUNING LLAMA3-8B\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. MONTAR DRIVE\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iXCi3Wd50rhf",
        "outputId": "e8ce9919-9888-4f83-a427-486bece0541e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. AUTENTICACION\n",
        "print(\"Autenticacion HuggingFace...\")\n",
        "try:\n",
        "    # Intentar usar Colab Secrets (recomendado)\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    login(token=hf_token)\n",
        "    print(\"✓ Autenticado con Colab Secrets\\n\")\n",
        "except:\n",
        "    # Fallback: pedir token manualmente\n",
        "    print(\" No se encontró HF_TOKEN en Colab Secrets\")\n",
        "    print(\"Configura el secreto o ingresa el token manualmente:\")\n",
        "    hf_token = input(\"Token de HuggingFace: \")\n",
        "    login(token=hf_token)\n",
        "    print(\" Autenticado manualmente\\n\")\n",
        "\n",
        "# 3. VERIFICAR GPU\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\\n\")\n"
      ],
      "metadata": {
        "id": "4aOiraeV0v0v",
        "outputId": "ffd55422-2e84-4b80-80ef-41fb9fa73c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "VRAM: 39.6 GB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. CARGAR MODELO\n",
        "print(\"Cargando Llama3-8B...\")\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "print(\"Modelo cargado\\n\")"
      ],
      "metadata": {
        "id": "ongb06Ev05Wn",
        "outputId": "0ab16e99-3729-4e99-b290-92dda5c1e220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "6878695c687143d2a028f794be3f16aa",
            "f0069b7199f64e07bce4b63faa88c10b",
            "216a11cbd89e466b80f01f5dc04de317",
            "5da85ef6271c48438245cc22d85bd882",
            "6b67363401ee4cd4b933ac108cf2bef1",
            "8584831baa904a6fab7c86c0db143c7b",
            "fb653cb8dd424888906455c876a37152",
            "15fd64ae5b634d24a3f31a0c708d44ec",
            "d733b393a9a64491aa44e447474235ba",
            "704d490a0b69481eb0085da33aeacce0",
            "a6c2c12bbcae4c28ad865153b72c9ebf"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando Llama3-8B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6878695c687143d2a028f794be3f16aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. LORA\n",
        "print(\"Configurando LoRA...\")\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Parametros entrenables: {trainable:,} ({100*trainable/total:.2f}%)\\n\")\n"
      ],
      "metadata": {
        "id": "q6zSAAg11C14",
        "outputId": "8a437051-3941-42c7-ab42-53e47e13d896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando LoRA...\n",
            "Parametros entrenables: 41,943,040 (0.52%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. DATASET\n",
        "print(\"Cargando dataset...\")\n",
        "dataset = load_dataset('json', data_files={\n",
        "    'train': '/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/dataset_train.json',\n",
        "    'test': '/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/dataset_val.json'\n",
        "})\n",
        "\n",
        "print(f\"Train: {len(dataset['train'])} ejemplos\")\n",
        "print(f\"Validation: {len(dataset['test'])} ejemplos\\n\")"
      ],
      "metadata": {
        "id": "UlrCzD2U1Om3",
        "outputId": "15247bbc-e976-4a7d-b65e-e5e52b97982f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando dataset...\n",
            "Train: 1350 ejemplos\n",
            "Validation: 150 ejemplos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. FORMATO (TRL 0.8.6)\n",
        "def formatting_func(example):\n",
        "    text = f\"\"\"### Instruccion:\n",
        "{example['instruction']}\n",
        "\n",
        "### Entrada:\n",
        "{example['input']}\n",
        "\n",
        "### Respuesta:\n",
        "{example['output']}\"\"\"\n",
        "    return [text]  # ← RETORNAR LISTA"
      ],
      "metadata": {
        "id": "TY4FiGkE1Qyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. ENTRENAMIENTO\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/outputs_llama3\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    max_steps=300,\n",
        "    warmup_steps=10,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    fp16=True,\n",
        "    save_strategy=\"steps\",\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "mJGDyntK1ZK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. TRAINER (TRL 0.8.6)\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset['train'],\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    formatting_func=formatting_func,\n",
        "    max_seq_length=2048,\n",
        ")"
      ],
      "metadata": {
        "id": "Q_wBY15k1eJ_",
        "outputId": "c60742f1-fda6-4c31-d7f4-bcd15730ba12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "3f2acff5e03747ea9ed517fbbdb9f2d1",
            "03ed6707ee544e2e9e6e86ec57e9b4c5",
            "0a316f4bfb504f1ca581b0cac3bcafcb",
            "a01e80191f634c56a67fc1a914b22de7",
            "a9d76df3304046ad9ade1c8c35601b51",
            "d8ba8cb7b062428480a21aa92b771b8b",
            "c7ca6431c2e342e08bbbc9b969e43b7b",
            "51f28df9a7a848daa606988c9124793b",
            "c0aed6f2a2b94fbb8538a5683a4b23aa",
            "7bfc39cfe8fd4fa4a9f779fa76bb8c8b",
            "28532c9d81364c54be29bfc8a281f5af"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f2acff5e03747ea9ed517fbbdb9f2d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. ENTRENAR\n",
        "print(\"=\"*70)\n",
        "print(\"INICIANDO ENTRENAMIENTO\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "inicio = time.time()\n",
        "trainer.train()\n",
        "tiempo = (time.time() - inicio) / 60\n",
        "\n",
        "print(f\"\\nTiempo: {tiempo:.1f} minutos\\n\")"
      ],
      "metadata": {
        "id": "4oshy3tj2Ajf",
        "outputId": "a7b5c033-e356-4685-dd52-c640a1d37da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "INICIANDO ENTRENAMIENTO\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 07:57, Epoch 300/300]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.555700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tiempo: 8.0 minutos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. GUARDAR\n",
        "model.save_pretrained(\"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_finetuned\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_finetuned\")\n",
        "\n",
        "print(\"MODELO GUARDADO\")\n",
        "print(\"FINE-TUNING COMPLETADO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxqTm1ws33-w",
        "outputId": "74e141d8-b164-49ed-a453-5c6e596d3dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODELO GUARDADO\n",
            "FINE-TUNING COMPLETADO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# FUSIONAR MODELO LLAMA3 + ADAPTADORES LORA\n",
        "# =========================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from huggingface_hub import login\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Autenticación HuggingFace\n",
        "login(token=\"hf_token\")\n",
        "\n",
        "print(\"Cargando modelo base...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "print(\"Cargando adaptadores LoRA...\")\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_finetuned\"\n",
        ")\n",
        "\n",
        "print(\"Fusionando modelo + adaptadores...\")\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "print(\"Guardando modelo fusionado...\")\n",
        "model.save_pretrained(\"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_merged\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_finetuned\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/PROYECTOS_IA/NLP/FINAL_NLP_ULTIMO3/fine_tuning_llama3/modelo_llama3_merged\")\n",
        "\n",
        "print(\"\\nMODELO FUSIONADO GUARDADO\")\n",
        "print(\"Carpeta: modelo_llama3_merged en Drive\")"
      ],
      "metadata": {
        "id": "eo9ffWbNSh2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6878695c687143d2a028f794be3f16aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0069b7199f64e07bce4b63faa88c10b",
              "IPY_MODEL_216a11cbd89e466b80f01f5dc04de317",
              "IPY_MODEL_5da85ef6271c48438245cc22d85bd882"
            ],
            "layout": "IPY_MODEL_6b67363401ee4cd4b933ac108cf2bef1"
          }
        },
        "f0069b7199f64e07bce4b63faa88c10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8584831baa904a6fab7c86c0db143c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_fb653cb8dd424888906455c876a37152",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "216a11cbd89e466b80f01f5dc04de317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15fd64ae5b634d24a3f31a0c708d44ec",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d733b393a9a64491aa44e447474235ba",
            "value": 4
          }
        },
        "5da85ef6271c48438245cc22d85bd882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704d490a0b69481eb0085da33aeacce0",
            "placeholder": "​",
            "style": "IPY_MODEL_a6c2c12bbcae4c28ad865153b72c9ebf",
            "value": " 4/4 [00:04&lt;00:00,  1.02it/s]"
          }
        },
        "6b67363401ee4cd4b933ac108cf2bef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8584831baa904a6fab7c86c0db143c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb653cb8dd424888906455c876a37152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15fd64ae5b634d24a3f31a0c708d44ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d733b393a9a64491aa44e447474235ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "704d490a0b69481eb0085da33aeacce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c2c12bbcae4c28ad865153b72c9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2acff5e03747ea9ed517fbbdb9f2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03ed6707ee544e2e9e6e86ec57e9b4c5",
              "IPY_MODEL_0a316f4bfb504f1ca581b0cac3bcafcb",
              "IPY_MODEL_a01e80191f634c56a67fc1a914b22de7"
            ],
            "layout": "IPY_MODEL_a9d76df3304046ad9ade1c8c35601b51"
          }
        },
        "03ed6707ee544e2e9e6e86ec57e9b4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ba8cb7b062428480a21aa92b771b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_c7ca6431c2e342e08bbbc9b969e43b7b",
            "value": "Map: 100%"
          }
        },
        "0a316f4bfb504f1ca581b0cac3bcafcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f28df9a7a848daa606988c9124793b",
            "max": 1350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0aed6f2a2b94fbb8538a5683a4b23aa",
            "value": 1350
          }
        },
        "a01e80191f634c56a67fc1a914b22de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bfc39cfe8fd4fa4a9f779fa76bb8c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_28532c9d81364c54be29bfc8a281f5af",
            "value": " 1350/1350 [00:00&lt;00:00, 1640.71 examples/s]"
          }
        },
        "a9d76df3304046ad9ade1c8c35601b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ba8cb7b062428480a21aa92b771b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ca6431c2e342e08bbbc9b969e43b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f28df9a7a848daa606988c9124793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0aed6f2a2b94fbb8538a5683a4b23aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bfc39cfe8fd4fa4a9f779fa76bb8c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28532c9d81364c54be29bfc8a281f5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}