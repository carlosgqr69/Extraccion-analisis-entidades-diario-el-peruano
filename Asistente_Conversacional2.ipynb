{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f523b2b3-d0ec-4ce0-8035-de155b0eba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando chromadb y sentence-transformers...\n",
      "Instalacion completada\n",
      "\n",
      "Librerias verificadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Instalando chromadb y sentence-transformers...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"chromadb\", \"sentence-transformers\"])\n",
    "print(\"Instalacion completada\")\n",
    "\n",
    "# Verificar\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "print(\"\\nLibrerias verificadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cceb7d5-7ae3-4253-9d0a-d32a374d59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SISTEMA DE CONSULTA DE AVISOS LEGALES\n",
      "Diario El Peruano - RAG + Fine-Tuning\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# ASISTENTE CONVERSACIONAL COMPLETO\n",
    "# RAG + Modelo Fine-Tuned para Avisos Legales\n",
    "# =========================================================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SISTEMA DE CONSULTA DE AVISOS LEGALES\")\n",
    "print(\"Diario El Peruano - RAG + Fine-Tuning\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4f5479-e9ee-4723-9124-b8b09d927720",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SISTEMA DE CONSULTA DE AVISOS LEGALES\n",
      "Diario El Peruano - RAG + Llama3-8B Fine-Tuned\n",
      "======================================================================\n",
      "\n",
      "Cargando base de datos RAG...\n",
      "   17,008 documentos cargados\n",
      "\n",
      "Cargando Llama3-8B fine-tuned...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e716b078cce94f5dbd6486ba637f978d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "The tokenizer you are loading from 'modelo_llama3_merged' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Modelo cargado\n",
      "\n",
      "SISTEMA LISTO\n",
      "\n",
      "Para iniciar el asistente, ejecuta:\n",
      ">>> asistente()\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CARGAR RAG + MODELO LLAMA3 FINE-TUNED\n",
    "# =========================================================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SISTEMA DE CONSULTA DE AVISOS LEGALES\")\n",
    "print(\"Diario El Peruano - RAG + Llama3-8B Fine-Tuned\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# 1. CARGAR RAG\n",
    "print(\"Cargando base de datos RAG...\")\n",
    "db_path = \"rag_database_final\"\n",
    "client = chromadb.PersistentClient(path=db_path)\n",
    "collection = client.get_collection(\"diario_final\")\n",
    "\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "print(f\"   {collection.count():,} documentos cargados\\n\")\n",
    "\n",
    "# 2. CARGAR MODELO LLAMA3 FUSIONADO\n",
    "print(\"Cargando Llama3-8B fine-tuned...\")\n",
    "\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(\n",
    "    \"modelo_llama3_merged\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer_ft = AutoTokenizer.from_pretrained(\"modelo_llama3_merged\")\n",
    "\n",
    "print(\"   Modelo cargado\\n\")\n",
    "\n",
    "# 3. FUNCIONES DEL ASISTENTE\n",
    "\n",
    "def consultar_rag(pregunta, top_k=5):\n",
    "    query_embedding = embed_model.encode(pregunta).tolist()\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    contexto = \"\"\n",
    "    if results['documents'] and len(results['documents']) > 0:\n",
    "        for doc in results['documents'][0]:\n",
    "            contexto += doc + \"\\n\\n\"\n",
    "    \n",
    "    return contexto.strip()\n",
    "\n",
    "def generar_respuesta(pregunta, contexto):\n",
    "    if not contexto:\n",
    "        return \"No encontre informacion relevante en la base de datos.\"\n",
    "    \n",
    "    prompt = f\"\"\"Eres un asistente especializado en avisos legales del Diario El Peruano. \n",
    "Responde la pregunta del usuario basandote en el contexto proporcionado.\n",
    "Se conciso y especifico.\n",
    "\n",
    "Contexto:\n",
    "{contexto[:1500]}\n",
    "\n",
    "Pregunta: {pregunta}\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer_ft(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(\"cuda\")\n",
    "    outputs = model_ft.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer_ft.eos_token_id\n",
    "    )\n",
    "    \n",
    "    respuesta = tokenizer_ft.decode(outputs[0], skip_special_tokens=True)\n",
    "    respuesta = respuesta.split(\"Respuesta:\")[-1].strip()\n",
    "    \n",
    "    return respuesta\n",
    "\n",
    "def asistente():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ASISTENTE DE AVISOS LEGALES - DIARIO EL PERUANO\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nPuedo ayudarte con:\")\n",
    "    print(\"   - Avisos de disolucion y liquidacion\")\n",
    "    print(\"   - Remates judiciales\")\n",
    "    print(\"   - Juntas de accionistas\")\n",
    "    print(\"   - Consultas por fecha, empresa o tipo\\n\")\n",
    "    \n",
    "    while True:\n",
    "        pregunta = input(\"\\nCual es su consulta? \").strip()\n",
    "        \n",
    "        if pregunta.lower() in ['salir', 'exit', 'chau']:\n",
    "            print(\"\\nGracias por usar el asistente. Hasta luego!\")\n",
    "            break\n",
    "        \n",
    "        if not pregunta:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\nBuscando en 17,008 documentos...\")\n",
    "        \n",
    "        contexto = consultar_rag(pregunta)\n",
    "        respuesta = generar_respuesta(pregunta, contexto)\n",
    "        \n",
    "        print(f\"\\n{respuesta}\")\n",
    "        \n",
    "        otra = input(\"\\nTiene otra pregunta? (si/no): \").strip().lower()\n",
    "        \n",
    "        if otra in ['no', 'ninguna', 'listo', 'gracias']:\n",
    "            print(\"\\nGracias por usar el asistente. Hasta luego!\")\n",
    "            break\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "print(\"SISTEMA LISTO\\n\")\n",
    "print(\"Para iniciar el asistente, ejecuta:\")\n",
    "print(\">>> asistente()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c44bfa-423e-461d-9e28-5017b7fba218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ASISTENTE DE AVISOS LEGALES - DIARIO EL PERUANO\n",
      "======================================================================\n",
      "\n",
      "Puedo ayudarte con:\n",
      "   - Avisos de disolucion y liquidacion\n",
      "   - Remates judiciales\n",
      "   - Juntas de accionistas\n",
      "   - Consultas por fecha, empresa o tipo\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Cual es su consulta?  quiero ver los remates judiciales de julio 2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando en 17,008 documentos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos\\anaconda3\\envs\\ft_final\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:413: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lo siento, pero como extrae información de ediciones anteriores, no tengo acceso a información de fechas futuras. Si necesitas información de remates judiciales de julio 2026, deberás revisar la edición del Diario El Peruano de ese mes. ¡Si necesitas ayuda con otra pregunta, estoy aquí! 1 A. Avisos Diversos 1 A. Edictos Judiciales 27 Titulos Supletorios • Reconocimiento de Unión de Hecho • • disolución respectivo, en cumplimiento estricto del marco legal aplicable, hasta que se inicie el proceso judicial de liquidación o se declare la quiebra judicial de la Coopac Nuevo Milenio en remate, mediante Constancia de Depó- ta para continuarla el día 30 DE JULIO DEL 2025 A HORAS rresponde a la deducción de las dos terceras\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiene otra pregunta? (si/no):  si\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Cual es su consulta?  quiero ver los remates judiciales de julio 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando en 17,008 documentos...\n",
      "\n",
      "Lee el aviso legal del Diario El Peruano de la fecha 04/08/2025, se procederá al\\n\\nRemate se tendrán por no presentadas y El martes 31 de Julio 2025, a partir de las 11:00 a.m. horas, se llevará a cabo el\\n\\nRemate, portando su documento de identidad y una copia, así como el original y copia de la vigencia de poder con una antigüedad no mayor a BASE LEGAL: treinta (30) días calendario a la fecha del\\n\\nRemate. Centro (e) S/ 578,582.82: Ate, Lima a S/ 578,582.82: San Martín de Porres, Lima a S/ 578,582.82: San Martín de Porres, Lima a S/ 578,582.82: San Martín de Porres, Lima a\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiene otra pregunta? (si/no):  que disoluciones y liquidaciones hubieron en mayo del 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Cual es su consulta?  que disoluciones y liquidaciones hubo en mayo del 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando en 17,008 documentos...\n"
     ]
    }
   ],
   "source": [
    "asistente()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087559c9-43e1-4722-b5f2-89b09526b30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (FT Final)",
   "language": "python",
   "name": "ft_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
