{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6ffcd4",
   "metadata": {
    "id": "9d6ffcd4"
   },
   "source": [
    "# üéôÔ∏è RAG por Voz ‚Äî DEMO v2.1 (Preflight + Fallback)\n",
    "\n",
    "Este cuaderno permite **preguntar por audio** y obtener **respuesta hablada** usando tu pipeline `rag_mejorado` (LlamaIndex + ChromaDB + Ollama).\n",
    "\n",
    "**Novedades v2.1**\n",
    "- Celda **preflight** que revisa e instala en el **kernel activo**: `ipywidgets`, `av`, `ffmpeg`, `torch`, `transformers`, `sentence-transformers`, `safetensors`, `ctranslate2`, `sentencepiece`, conectores de **LlamaIndex** y `chromadb`.\n",
    "- **Quick fix de DLLs** para Windows: agrega rutas de `Library/bin` del entorno a la b√∫squeda de DLLs antes de importar `av`/`faster_whisper`.\n",
    "- STT con **fallback autom√°tico**: intenta `CPU int8_float16` y si no es compatible, cae a `CPU float32` (modelo `base`).\n",
    "\n",
    "> Sugerido: Python ‚â• 3.10 (ideal 3.12) y **Ollama** ejecut√°ndose con `llama3` o `llama3:2`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c42e5b",
   "metadata": {
    "id": "32c42e5b"
   },
   "source": [
    "## 1) Preflight ‚Äî diagn√≥stico e instalaci√≥n en el kernel activo\n",
    "Ejecuta esta celda **primero**. Si instala algo, **reinicia el kernel** y vuelve a correr desde aqu√≠.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c35ed",
   "metadata": {
    "id": "897c35ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Preflight en kernel ==> C:\\Users\\user\\anaconda3\\envs\\PLN\\python.exe\n",
      "SO: Windows-10-10.0.22631-SP0\n",
      "[OK] ipywidgets\n",
      "[OK] jupyterlab_widgets\n",
      "[OK] av\n",
      "[OK] ffmpeg en PATH: C:\\Users\\user\\anaconda3\\envs\\PLN\\Library\\bin\\ffmpeg.EXE\n",
      "[OK] torch 2.9.1+cpu\n",
      "[OK] transformers\n",
      "[OK] sentence_transformers\n",
      "[OK] safetensors\n",
      "[OK] ctranslate2\n",
      "[OK] sentencepiece\n",
      "[OK] faster_whisper\n",
      "[OK] llama_index\n",
      "[OK] llama_index.vector_stores.chroma\n",
      "[OK] llama_index.llms.ollama\n",
      "[OK] llama_index.embeddings.huggingface\n",
      "[OK] chromadb\n",
      "\n",
      "== Resumen ==\n",
      "ffmpeg PATH: C:\\Users\\user\\anaconda3\\envs\\PLN\\Library\\bin\\ffmpeg.EXE\n",
      "Cambios realizados (instalaciones): False\n",
      "\n",
      "‚úÖ Todo listo. No es necesario reiniciar el kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === PRE-FLIGHT ===\n",
    "import sys, os, importlib, subprocess, platform, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"== Preflight en kernel ==>\", sys.executable)\n",
    "print(\"SO:\", platform.platform())\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def run_pip(*pkgs):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-U\"] + list(pkgs)\n",
    "    print(\">>\", \" \".join(cmd))\n",
    "    return subprocess.call(cmd)\n",
    "\n",
    "def run_conda(*pkgs):\n",
    "    conda_exe = shutil.which(\"conda\")\n",
    "    if not conda_exe:\n",
    "        print(\"(!) 'conda' no est√° en PATH de este kernel; saltando conda.\")\n",
    "        return 1\n",
    "    cmd = [conda_exe, \"install\", \"-y\", \"-c\", \"conda-forge\"] + list(pkgs)\n",
    "    print(\">>\", \" \".join(cmd))\n",
    "    return subprocess.call(cmd)\n",
    "\n",
    "def ensure_import(mod_name, pip_pkg=None, conda_pkg=None):\n",
    "    try:\n",
    "        importlib.import_module(mod_name)\n",
    "        print(f\"[OK] {mod_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"[FALTA] {mod_name} ({type(e).__name__}: {e})\")\n",
    "        changed = False\n",
    "        if conda_pkg:\n",
    "            rc = run_conda(conda_pkg)\n",
    "            changed |= (rc == 0)\n",
    "            try:\n",
    "                importlib.import_module(mod_name)\n",
    "                print(f\"[OK] {mod_name} (via conda)\")\n",
    "                return True\n",
    "            except Exception as e2:\n",
    "                print(f\"[A√öN FALTA] {mod_name} tras conda: {e2}\")\n",
    "        if pip_pkg:\n",
    "            rc = run_pip(pip_pkg)\n",
    "            changed |= (rc == 0)\n",
    "            try:\n",
    "                importlib.import_module(mod_name)\n",
    "                print(f\"[OK] {mod_name} (via pip)\")\n",
    "                return True\n",
    "            except Exception as e3:\n",
    "                print(f\"[A√öN FALTA] {mod_name} tras pip: {e3}\")\n",
    "        return changed\n",
    "\n",
    "changed_any = False\n",
    "\n",
    "# ipywidgets\n",
    "changed_any |= ensure_import(\"ipywidgets\", pip_pkg=\"ipywidgets\")\n",
    "changed_any |= ensure_import(\"jupyterlab_widgets\", pip_pkg=\"jupyterlab_widgets\")\n",
    "\n",
    "# AV y FFmpeg\n",
    "changed_any |= ensure_import(\"av\", pip_pkg=\"av\", conda_pkg=\"av\")\n",
    "from shutil import which as _which\n",
    "ffmpeg_path = _which(\"ffmpeg\")\n",
    "if ffmpeg_path:\n",
    "    print(f\"[OK] ffmpeg en PATH: {ffmpeg_path}\")\n",
    "else:\n",
    "    print(\"[FALTA] ffmpeg en PATH; intentando instalar con conda-forge...\")\n",
    "    rc = run_conda(\"ffmpeg\")\n",
    "    ffmpeg_path = _which(\"ffmpeg\")\n",
    "    if ffmpeg_path:\n",
    "        print(f\"[OK] ffmpeg instalado: {ffmpeg_path}\")\n",
    "        changed_any = True\n",
    "    else:\n",
    "        print(\"[ATENCI√ìN] ffmpeg sigue no disponible. A√±ade manualmente la carpeta 'bin' de ffmpeg al PATH o reinstala con conda.\")\n",
    "\n",
    "# Torch CPU si falta\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"[OK] torch {torch.__version__}\")\n",
    "except Exception:\n",
    "    print(\"[FALTA] torch (CPU) ‚Üí instalando desde √≠ndice oficial de PyTorch CPU...\")\n",
    "    rc = subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\",\n",
    "                          \"torch==2.2.2+cpu\", \"--index-url\", \"https://download.pytorch.org/whl/cpu\"])\n",
    "    changed_any |= (rc == 0)\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"[OK] torch {torch.__version__}\")\n",
    "    except Exception as e:\n",
    "        print(\"[A√öN FALTA] torch tras instalaci√≥n:\", e)\n",
    "\n",
    "# HF stack\n",
    "changed_any |= ensure_import(\"transformers\", pip_pkg=\"transformers\")\n",
    "changed_any |= ensure_import(\"sentence_transformers\", pip_pkg=\"sentence-transformers\")\n",
    "changed_any |= ensure_import(\"safetensors\", pip_pkg=\"safetensors\")\n",
    "\n",
    "# faster-whisper backend\n",
    "changed_any |= ensure_import(\"ctranslate2\", pip_pkg=\"ctranslate2\")\n",
    "changed_any |= ensure_import(\"sentencepiece\", pip_pkg=\"sentencepiece\")\n",
    "changed_any |= ensure_import(\"faster_whisper\", pip_pkg=\"faster-whisper\")\n",
    "\n",
    "# LlamaIndex split packages\n",
    "changed_any |= ensure_import(\"llama_index\", pip_pkg=\"llama-index==0.10.54\")\n",
    "changed_any |= ensure_import(\"llama_index.vector_stores.chroma\", pip_pkg=\"llama-index-vector-stores-chroma\")\n",
    "changed_any |= ensure_import(\"llama_index.llms.ollama\", pip_pkg=\"llama-index-llms-ollama\")\n",
    "changed_any |= ensure_import(\"llama_index.embeddings.huggingface\", pip_pkg=\"llama-index-embeddings-huggingface\")\n",
    "changed_any |= ensure_import(\"chromadb\", pip_pkg=\"chromadb==0.5.5\")\n",
    "\n",
    "print(\"\\n== Resumen ==\")\n",
    "print(\"ffmpeg PATH:\", ffmpeg_path or \"(no encontrado)\")\n",
    "print(\"Cambios realizados (instalaciones):\", changed_any)\n",
    "\n",
    "if changed_any:\n",
    "    print(\"\\n‚ö†Ô∏è Se instalaron/actualizaron dependencias en este kernel.\")\n",
    "    print(\"‚û°Ô∏è Por favor, **reinicia el kernel** (Kernel ‚Üí Restart) y vuelve a ejecutar desde esta celda.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Todo listo. No es necesario reiniciar el kernel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de908a0",
   "metadata": {
    "id": "8de908a0"
   },
   "source": [
    "## 2) Cargar `rag_mejorado`\n",
    "- Si es **.ipynb**, usa `%run rag_mejorado.ipynb`.\n",
    "- Si es **.py**, se importar√° como m√≥dulo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f19cab",
   "metadata": {
    "id": "38f19cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> C:\\Users\\user\\anaconda3\\envs\\PLN\\python.exe -m pip install -U llama-index>=0.11.20 llama-index-llms-ollama>=0.2.2 llama-index-embeddings-huggingface>=0.2.4 llama-index-vector-stores-chroma>=0.2.0 chromadb>=0.5.5 sentence-transformers>=3.0.0 pandas>=2.1.0\n",
      "‚úÖ Dependencias instaladas/actualizadas correctamente.\n",
      "‚úÖ M√≥dulo disponible: llama_index\n",
      "‚úÖ M√≥dulo disponible: llama_index.llms.ollama\n",
      "‚úÖ M√≥dulo disponible: llama_index.vector_stores.chroma\n",
      "‚úÖ M√≥dulo disponible: chromadb\n",
      "\n",
      "‚úÖ Preflight + Imports + Configuraci√≥n completados.\n",
      "Imports configurados\n",
      "Metodolog√≠a basada en: Rangan & Yin (2024) - RAG + Fine-tuning\n",
      "======================================================================\n",
      "CARGANDO CSV ORIGINAL\n",
      "======================================================================\n",
      "\n",
      "Total registros: 2,977,413\n",
      "Registros relevantes: 16,724\n",
      "\n",
      "Distribuci√≥n por tipo:\n",
      "tipo\n",
      "REMATE               9282\n",
      "JUNTA_ACCIONISTAS    3772\n",
      "DISOLUCION           3670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "EXTRAYENDO EMPRESAS DEL TEXTO COMPLETO\n",
      "======================================================================\n",
      "\n",
      "Extrayendo... (2-3 minutos)\n",
      "\n",
      "Completado en 0.5 segundos\n",
      "\n",
      "Resultados:\n",
      "  Total: 16,724\n",
      "  Extra√≠das: 3,011 (18.0%)\n",
      "  No extra√≠das: 13,713\n",
      "\n",
      "Desglose por tipo:\n",
      "  JUNTA_ACCIONISTAS: 1384/3772 (36.7%)\n",
      "  DISOLUCION: 373/3670 (10.2%)\n",
      "  REMATE: 1254/9282 (13.5%)\n",
      "\n",
      "Guardando CSV mejorado...\n",
      "Guardado: base_datos_completa_mejorada.csv\n",
      "======================================================================\n",
      "CREANDO RAG CON TEXTO COMPLETO\n",
      "Estrategia: Dejar que el LLM extraiga del texto\n",
      "======================================================================\n",
      "\n",
      "16,724 documentos creados\n",
      "\n",
      "Creando chunks (tama√±o 800)...\n",
      "16,724 chunks creados\n",
      "\n",
      "Creando base de datos vectorial...\n",
      "Creando √≠ndice vectorial (5-10 min)...\n",
      "\n",
      "\n",
      "16,724 vectores creados en 3.0 minutos\n",
      "Base de datos guardada en: rag_database_final/\n",
      "Funci√≥n consultar_rag_final() lista\n",
      "======================================================================\n",
      "PRUEBA: RAG FINAL (LLM extrae del texto)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "M√âTRICAS:\n",
      "  Documentos recuperados: 8\n",
      "  Tiempo total: 5.3s\n",
      "  Tiempo LLM: 5.2s\n",
      "  Score promedio: 0.817\n",
      "\n",
      "RESPUESTA DEL LLM:\n",
      "Seg√∫n los documentos legales del Diario Oficial El Peruano, las empresas que fueron disueltas en octubre de 2025 son:\n",
      "\n",
      "* CORPORACION ALP S.A.C. (con RUC 20606762845) - fecha: 1 de octubre de 2025\n",
      "* FL Perishables S.A.C. (con RUC no especificado) - fecha: 1 de octubre de 2025\n",
      "* OEM ORIGINAL MOTO S.R.L. (con RUC no especificado) - fecha: 18 de septiembre de 2024, extendida hasta el 1 de octubre de 2025\n",
      "\n",
      "Nota: Los documentos no proporcionan informaci√≥n adicional sobre la disoluci√≥n y liquidaci√≥n de estas empresas.\n",
      "\n",
      "======================================================================\n",
      "DOCUMENTOS RECUPERADOS (primeros 5)\n",
      "======================================================================\n",
      "\n",
      "1. Score: 0.831\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-10-06\n",
      "   Texto (150 chars): DISOLUCION Y LIQUIDACION Por acuerdo de los Accionistas del 22/09/2025, y de conformidad con el Art 419 de la L.G.S, se aprob√≥ POR ACTA DE DECISI√ìN DE...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.820\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-10-29\n",
      "   Texto (150 chars): disoluci√≥n y CONSTRUCCIONES CIMA E.I.R.L. DECIDI√ì TRANSFOR- de fecha 09/10/2025 se aprob√≥ la Transformaci√≥n liquidaci√≥n de la empresa FERRI INDUSTRIAL...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.820\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-10-30\n",
      "   Texto (150 chars): DISOLUCI√ìN ‚Äú DICE‚Äù : Segunda convocatora d√≠a 03 Sociedades, se informa que, mediante Junta y LIQUIDACI√ìN, de la Empresa Multinegocios ‚Äú7 y LIQUIDACI√ìN...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "4. Score: 0.818\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-10-21\n",
      "   Texto (150 chars): disoluci√≥n y liquidaci√≥n de CORPORACION ALP octubre de 2025, de conformidad con la L.G.S., De conformidad con lo dispuesto por el art√≠culo de FLP del ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "5. Score: 0.814\n",
      "   Tipo: DISOLUCION\n",
      "   Fecha: 2025-10-26\n",
      "   Texto (150 chars): Disoluci√≥n y 2023, 07 DE MARZO DE 2024, 27 DE MARZO DE y Org√°nica de la Superintendencia de Banca y Banca y Seguros ‚Äì informamos, que mediante Liquida...\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "EVALUACI√ìN CUANTITATIVA - RAG FINAL\n",
      "======================================================================\n",
      "\n",
      "Queries evaluadas: 6\n",
      "\n",
      "RESULTADOS:\n",
      "  Precision tipo: 100.0%\n",
      "  Precision mes: 100.0%\n",
      "  Empresas promedio por respuesta: 2.8\n",
      "  Tiempo promedio: 2.3s\n",
      "\n",
      "Desglose:\n",
      "                                 query               tipo  precision_tipo  \\\n",
      "0  ¬øQu√© empresas fueron disueltas en o         DISOLUCION             1.0   \n",
      "1  ¬øQu√© empresas fueron disueltas en n         DISOLUCION             1.0   \n",
      "2              Remates en octubre 2025             REMATE             1.0   \n",
      "3            Remates en noviembre 2025             REMATE             1.0   \n",
      "4  Juntas de accionistas en octubre 20  JUNTA_ACCIONISTAS             1.0   \n",
      "5  Juntas de accionistas en noviembre   JUNTA_ACCIONISTAS             1.0   \n",
      "\n",
      "   precision_mes  empresas_aprox    tiempo  \n",
      "0            1.0               1  1.144667  \n",
      "1            1.0               4  1.571667  \n",
      "2            1.0               0  1.282081  \n",
      "3            1.0               0  2.617596  \n",
      "4            1.0               4  4.173953  \n",
      "5            1.0               8  2.811351  \n",
      "======================================================================\n",
      "DOCUMENTACI√ìN - RESULTADOS DEL RAG FINAL\n",
      "======================================================================\n",
      "\n",
      "\n",
      "# SISTEMA RAG - DIARIO EL PERUANO\n",
      "# Resultados Finales\n",
      "\n",
      "## 1. ARQUITECTURA IMPLEMENTADA\n",
      "\n",
      "- Embeddings: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "  * Dimensiones: 384\n",
      "  * Optimizado para espa√±ol\n",
      "  * 118M par√°metros\n",
      "\n",
      "- Vector Store: ChromaDB\n",
      "  * Algoritmo: HNSW (Hierarchical Navigable Small World)\n",
      "  * M√©trica: Similitud coseno\n",
      "  * Vectores totales: 16,724\n",
      "  * Persistencia: Local (rag_database_final/)\n",
      "\n",
      "- LLM: Llama3-8B\n",
      "  * Deployment: Local via Ollama\n",
      "  * Uso: Generaci√≥n y extracci√≥n de informaci√≥n\n",
      "  * Contexto: 8K tokens\n",
      "\n",
      "## 2. DATOS\n",
      "\n",
      "- Registros totales procesados: 2,977,413\n",
      "- Registros relevantes (3 tipos): 16,724\n",
      "  * Disoluciones: 3,670\n",
      "  * Remates: 9,282\n",
      "  * Juntas: 3,772\n",
      "\n",
      "- Periodo: Abril - Noviembre 2025 (8 meses)\n",
      "- Chunks creados: 16,724\n",
      "- Tama√±o chunk: 800 tokens (overlap 100)\n",
      "\n",
      "## 3. ESTRATEGIA DE PROCESAMIENTO\n",
      "\n",
      "Inicial: Extracci√≥n estructurada con regex\n",
      "- √âxito: 17.9%\n",
      "- Problema: Textos mal formateados en CSV\n",
      "\n",
      "Final: Texto completo sin pre-extracci√≥n\n",
      "- El LLM extrae informaci√≥n del texto\n",
      "- M√°s robusto con datos reales\n",
      "- Approach respaldado por papers (Rangan & Yin, 2024)\n",
      "\n",
      "## 4. RECUPERACI√ìN (RETRIEVAL)\n",
      "\n",
      "Proceso:\n",
      "1. Query ‚Üí Embedding (384D)\n",
      "2. B√∫squeda similitud en ChromaDB\n",
      "3. Filtros metadata (tipo, mes, a√±o) - Exact match\n",
      "4. Reranking: 60% similitud + 40% metadata\n",
      "5. Top-K: 8 documentos finales\n",
      "\n",
      "## 5. M√âTRICAS DE EVALUACI√ìN\n",
      "\n",
      "Queries evaluadas: 6\n",
      "Tipos evaluados: DISOLUCION, REMATE, JUNTA_ACCIONISTAS\n",
      "\n",
      "RESULTADOS:\n",
      "- Precision tipo: 100%\n",
      "- Precision mes: 100%\n",
      "- Empresas promedio por respuesta: 7.2\n",
      "- Tiempo promedio: 38.4s\n",
      "\n",
      "Desglose por tipo:\n",
      "                   precision_tipo  precision_mes\n",
      "tipo                                            \n",
      "DISOLUCION                    1.0            1.0\n",
      "JUNTA_ACCIONISTAS             1.0            1.0\n",
      "REMATE                        1.0            1.0\n",
      "\n",
      "## 6. VENTAJAS DEL SISTEMA\n",
      "\n",
      " 100% local (sin APIs de pago)\n",
      " Sin costos operativos\n",
      " Privacidad garantizada (datos no salen)\n",
      " Filtros metadata precisos (100%)\n",
      " Robusto con datos reales (con ruido)\n",
      " Escalable (millones de documentos)\n",
      " Verificable (citas a documentos fuente)\n",
      "\n",
      "## 7. LIMITACIONES IDENTIFICADAS\n",
      "\n",
      " Tiempo de respuesta: 30-65s (principalmente LLM)\n",
      " Calidad depende del texto original en PDFs\n",
      " Corpus limitado a 8 meses (expandible)\n",
      "\n",
      "## 8. PR√ìXIMOS PASOS\n",
      "\n",
      " Fine-tuning de Llama3 para formateo de respuestas\n",
      " Optimizaci√≥n de velocidad (caching, streaming)\n",
      " Expansi√≥n del corpus (a√±os anteriores)\n",
      " Interfaz web (Streamlit/Gradio)\n",
      "\n",
      "---\n",
      "Generado: 2026-01-12 16:44:09\n",
      "\n",
      "\n",
      " Documentaci√≥n guardada: RESULTADOS_RAG_FINAL.txt\n",
      "No se pudo importar 'RAG_LLAMA3.py'. Si lo tienes como .ipynb usa: %run RAG_LLAMA3.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üëâ Descomenta si tu archivo es notebook:\n",
    "%run RAG_LLAMA3.ipynb\n",
    "\n",
    "# üëâ Si es .py, intenta importarlo:\n",
    "try:\n",
    "    import importlib\n",
    "    rag = importlib.import_module('RAG_LLAMA3')\n",
    "    from RAG_LLAMA3 import consultar_rag_databse_final\n",
    "    print(\"Importado 'RAG_LLAMA3' como m√≥dulo.\")\n",
    "    try:\n",
    "        print(\"Vectores en colecci√≥n:\", rag.chroma_collection_final.count())\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo leer conteo de vectores:\", e)\n",
    "except Exception as e:\n",
    "    print(\"No se pudo importar 'RAG_LLAMA3.py'. Si lo tienes como .ipynb usa: %run RAG_LLAMA3.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf357e30",
   "metadata": {
    "id": "cf357e30"
   },
   "source": [
    "## 3) Verificar Ollama y configurar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7abef4",
   "metadata": {
    "id": "5f7abef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED     \n",
      "llama3:latest      365c0bd3c000    4.7 GB    38 hours ago    \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    8 days ago      \n",
      "\n",
      "Modelo sugerido: llama3\n",
      "LLM configurado con: llama3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess, re\n",
    "from llama_index.core import Settings\n",
    "\n",
    "out = subprocess.run(\"ollama list\", shell=True, capture_output=True, text=True)\n",
    "print(out.stdout or out.stderr)\n",
    "model_name = None\n",
    "if \"llama3:2\" in (out.stdout or \"\"):\n",
    "    model_name = \"llama3:2\"\n",
    "elif re.search(r\"\\bllama3\\b\", out.stdout or \"\"):\n",
    "    model_name = \"llama3\"\n",
    "print(\"Modelo sugerido:\", model_name or \"(aj√∫stalo manualmente si es necesario)\")\n",
    "\n",
    "try:\n",
    "    from llama_index.llms.ollama import Ollama\n",
    "    if model_name:\n",
    "        Settings.llm = Ollama(model=model_name, request_timeout=300.0,\n",
    "                              system_prompt=(\n",
    "                                  \"Eres un asistente experto en documentos legales peruanos. \"\n",
    "                                  \"Responde en espa√±ol usando solo el contexto.\"\n",
    "                              ))\n",
    "        print(\"LLM configurado con:\", model_name)\n",
    "except Exception as e:\n",
    "    print(\"No fue posible configurar Ollama:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1dd7e",
   "metadata": {
    "id": "63b1dd7e"
   },
   "source": [
    "## 4) Quick fix DLLs (Windows)\n",
    "Si est√°s en Windows y PyAV/FFmpeg dan **DLL load failed**, ejecuta esta celda **antes** de importar `faster_whisper`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cee05c",
   "metadata": {
    "id": "d9cee05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A√±adido al buscador de DLLs: C:\\Users\\user\\anaconda3\\envs\\PLN\\Library\\bin\n",
      "A√±adido al buscador de DLLs: C:\\Users\\user\\anaconda3\\envs\\PLN\\DLLs\n",
      "A√±adido al buscador de DLLs: C:\\Users\\user\\anaconda3\\envs\\PLN\\Scripts\n",
      "PyAV OK: 16.1.0 | ffmpeg: C:\\Users\\user\\anaconda3\\envs\\PLN\\Library\\bin\\ffmpeg.exe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "base = sys.prefix\n",
    "add_dirs = [\n",
    "    os.path.join(base, \"Library\", \"bin\"),\n",
    "    os.path.join(base, \"DLLs\"),\n",
    "    os.path.join(base, \"Scripts\"),\n",
    "]\n",
    "for d in add_dirs:\n",
    "    if os.path.isdir(d):\n",
    "        try:\n",
    "            os.add_dll_directory(d)\n",
    "            print(\"A√±adido al buscador de DLLs:\", d)\n",
    "        except Exception as e:\n",
    "            print(\"No se pudo a√±adir\", d, e)\n",
    "\n",
    "# Prueba r√°pida\n",
    "try:\n",
    "    import av\n",
    "    from pydub.utils import which\n",
    "    print(\"PyAV OK:\", getattr(av, '__version__', 'OK'), \"| ffmpeg:\", which(\"ffmpeg\") or \"(no en PATH)\")\n",
    "except Exception as e:\n",
    "    print(\"PyAV a√∫n falla:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297cb93",
   "metadata": {
    "id": "f297cb93"
   },
   "source": [
    "## 5) DEMO por voz (Gradio) ‚Äî Fallback autom√°tico\n",
    "- Transcripci√≥n con `faster-whisper` (CPU `int8_float16` ‚Üí `float32` si falla).\n",
    "- Consulta `consultar_rag_final(...)`.\n",
    "- TTS con `pyttsx3`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebecab",
   "metadata": {
    "id": "68ebecab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg: C:\\Users\\user\\anaconda3\\envs\\PLN\\Library\\bin\\ffmpeg.exe\n",
      "STT: int8_float16 no disponible ‚Üí usando CPU float32 (motivo: ValueError)\n",
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\PLN\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\PLN\\lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n",
      "Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)\n",
      "handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\PLN\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\PLN\\lib\\asyncio\\proactor_events.py\", line 165, in _call_connection_lost\n",
      "    self._sock.shutdown(socket.SHUT_RDWR)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "import tempfile, os\n",
    "from faster_whisper import WhisperModel\n",
    "import pyttsx3\n",
    "from pydub.utils import which\n",
    "\n",
    "print(\"ffmpeg:\", which(\"ffmpeg\") or \"(no encontrado)\")\n",
    "\n",
    "# --- STT con fallback ---\n",
    "stt_info = \"\"\n",
    "\n",
    "def build_stt_model():\n",
    "    global stt_info\n",
    "    try:\n",
    "        m = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8_float16\")\n",
    "        stt_info = \"STT: CPU int8_float16\"\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        stt_info = f\"STT: int8_float16 no disponible ‚Üí usando CPU float32 (motivo: {type(e).__name__})\"\n",
    "        return WhisperModel(\"base\", device=\"cpu\", compute_type=\"float32\")\n",
    "\n",
    "stt_model = build_stt_model()\n",
    "print(stt_info)\n",
    "\n",
    "# --- TTS ---\n",
    "tts_engine = pyttsx3.init()\n",
    "tts_engine.setProperty('rate', 170)\n",
    "tts_engine.setProperty('volume', 1.0)\n",
    "\n",
    "TIPOS = [\"\", \"DISOLUCION\", \"REMATE\", \"JUNTA_ACCIONISTAS\"]\n",
    "\n",
    "def transcribir(audio_path: str) -> str:\n",
    "    segments, info = stt_model.transcribe(audio_path, language=\"es\", beam_size=5)\n",
    "    return \" \".join([s.text.strip() for s in segments]).strip()\n",
    "\n",
    "def tts_to_wav(text: str) -> str:\n",
    "    tmp_wav = tempfile.mktemp(suffix=\".wav\")\n",
    "    tts_engine.save_to_file(text, tmp_wav)\n",
    "    tts_engine.runAndWait()\n",
    "    return tmp_wav\n",
    "\n",
    "def rag_voice_pipeline(audio, tipo, mes, anio, top_k):\n",
    "    if audio is None:\n",
    "        return \"No se recibi√≥ audio.\", None\n",
    "\n",
    "    audio_path = audio  # Gradio entrega filepath\n",
    "\n",
    "    # 1) STT\n",
    "    try:\n",
    "        pregunta = transcribir(audio_path)\n",
    "    except Exception as e:\n",
    "        return f\"Error al transcribir: {type(e).__name__} - {e}\", None\n",
    "\n",
    "    # 2) Normalizar filtros\n",
    "    tipo = (tipo or \"\").strip() or None\n",
    "    mes  = (mes or \"\").strip() or None\n",
    "    if mes and len(mes) == 1:\n",
    "        mes = mes.zfill(2)\n",
    "    anio = (anio or \"\").strip() or '2025'\n",
    "\n",
    "    # 3) Consultar RAG\n",
    "    try:\n",
    "        resp, nodes, t = consultar_rag_final(pregunta, tipo=tipo, mes=mes, a√±o=anio, top_k=int(top_k), verbose=False)\n",
    "        if not resp:\n",
    "            resp = \"No se encontr√≥ contexto suficiente para responder con precisi√≥n.\"\n",
    "    except Exception as e:\n",
    "        resp = f\"Error al consultar RAG: {type(e).__name__} - {e}\"\n",
    "        nodes = []\n",
    "\n",
    "    # 4) Resumen nodos (Top 5)\n",
    "    resumen = []\n",
    "    for n in nodes[:5]:\n",
    "        resumen.append(f\"‚Ä¢ score={getattr(n,'score',None):.3f} | tipo={n.metadata.get('tipo')} | fecha={n.metadata.get('fecha')} | mes={n.metadata.get('mes')} | a√±o={n.metadata.get('a√±o')}\")\n",
    "    resumen_md = \"\\n\".join(resumen) if resumen else \"(Sin nodos recuperados)\"\n",
    "\n",
    "    # 5) TTS\n",
    "    try:\n",
    "        wav_out = tts_to_wav(resp)\n",
    "    except Exception:\n",
    "        wav_out = None\n",
    "\n",
    "    texto_md = (\n",
    "        f\"**Modo STT:** {stt_info}\\n\\n\"\n",
    "        f\"**Pregunta (transcrita):** {pregunta}\\n\\n\"\n",
    "        f\"**Respuesta:**\\n\\n{resp}\\n\\n\"\n",
    "        f\"**Nodos (Top 5):**\\n\\n{resumen_md}\"\n",
    "    )\n",
    "    return texto_md, wav_out\n",
    "\n",
    "with gr.Blocks(title=\"RAG por Voz ‚Äî v2.1 (preflight + fallback)\") as demo:\n",
    "    gr.Markdown(\"## üéôÔ∏è Pregunta por voz y respuesta hablada\")\n",
    "    audio_in = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"Audio (micr√≥fono o archivo)\")\n",
    "    with gr.Row():\n",
    "        tipo_in = gr.Dropdown(choices=TIPOS, value=\"\", label=\"Tipo (opcional)\")\n",
    "        mes_in  = gr.Textbox(value=\"\", label=\"Mes (MM)\")\n",
    "        anio_in = gr.Textbox(value=\"2025\", label=\"A√±o (YYYY)\")\n",
    "        topk_in = gr.Slider(3, 20, value=8, step=1, label=\"Top-K\")\n",
    "    btn = gr.Button(\"üîé Consultar\")\n",
    "    texto_out = gr.Markdown()\n",
    "    audio_out = gr.Audio(label=\"Respuesta en audio\", type=\"filepath\")\n",
    "\n",
    "    btn.click(rag_voice_pipeline, inputs=[audio_in, tipo_in, mes_in, anio_in, topk_in], outputs=[texto_out, audio_out])\n",
    "\n",
    "# Ejecutar la app\n",
    "demo.launch(inbrowser=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdab31-8084-472e-9f0b-8cc40e6d9705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:PLN]",
   "language": "python",
   "name": "conda-env-PLN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
